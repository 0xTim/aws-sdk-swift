// THIS FILE IS AUTOMATICALLY GENERATED. DO NOT EDIT.
/**
The MIT License (MIT)

Copyright (c) 2017 Yuki Takei(noppoMan)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

*/

import Foundation
import Core

extension Firehose {

    public struct ProcessingConfiguration: Serializable, Initializable {
        /// The data processors.
        var processors: [Processor]? = nil
        /// Enables or disables data processing.
        var enabled: Bool? = nil

        public init() {}

        public init(processors: [Processor]? = nil, enabled: Bool? = nil) {
            self.processors = processors
            self.enabled = enabled
        }

    }

    public struct DescribeDeliveryStreamOutput: Serializable, Initializable {
        /// Information about the delivery stream.
        var deliveryStreamDescription: DeliveryStreamDescription = DeliveryStreamDescription()

        public init() {}

        public init(deliveryStreamDescription: DeliveryStreamDescription) {
            self.deliveryStreamDescription = deliveryStreamDescription
        }

    }

    public struct RedshiftDestinationConfiguration: Serializable, Initializable {
        /// The COPY command.
        var copyCommand: CopyCommand = CopyCommand()
        /// The configuration for the intermediate Amazon S3 location from which Amazon Redshift obtains data. Restrictions are described in the topic for CreateDeliveryStream. The compression formats SNAPPY or ZIP cannot be specified in RedshiftDestinationConfiguration.S3Configuration because the Amazon Redshift COPY operation that reads from the S3 bucket doesn't support these compression formats.
        var s3Configuration: S3DestinationConfiguration = S3DestinationConfiguration()
        /// The ARN of the AWS credentials.
        var roleARN: String = ""
        /// The name of the user.
        var username: String = ""
        /// The configuration for backup in Amazon S3.
        var s3BackupConfiguration: S3DestinationConfiguration? = nil
        /// The database connection string.
        var clusterJDBCURL: String = ""
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The user password.
        var password: String = ""
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).
        var retryOptions: RedshiftRetryOptions? = nil
        /// The Amazon S3 backup mode.
        var s3BackupMode: String? = nil

        public init() {}

        public init(copyCommand: CopyCommand, s3Configuration: S3DestinationConfiguration, roleARN: String, username: String, s3BackupConfiguration: S3DestinationConfiguration? = nil, clusterJDBCURL: String, processingConfiguration: ProcessingConfiguration? = nil, password: String, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: RedshiftRetryOptions? = nil, s3BackupMode: String? = nil) {
            self.copyCommand = copyCommand
            self.s3Configuration = s3Configuration
            self.roleARN = roleARN
            self.username = username
            self.s3BackupConfiguration = s3BackupConfiguration
            self.clusterJDBCURL = clusterJDBCURL
            self.processingConfiguration = processingConfiguration
            self.password = password
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.s3BackupMode = s3BackupMode
        }

    }

    public struct CopyCommand: Serializable, Initializable {
        /// The name of the target table. The table must already exist in the database.
        var dataTableName: String = ""
        /// A comma-separated list of column names.
        var dataTableColumns: String? = nil
        /// Optional parameters to use with the Amazon Redshift COPY command. For more information, see the "Optional Parameters" section of Amazon Redshift COPY command. Some possible examples that would apply to Firehose are as follows:  delimiter '\t' lzop; - fields are delimited with "\t" (TAB character) and compressed using lzop.  delimiter '| - fields are delimited with "|" (this is the default delimiter).  delimiter '|' escape - the delimiter should be escaped.  fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6' - fields are fixed width in the source, with each width specified after every column in the table.  JSON 's3://mybucket/jsonpaths.txt' - data is in JSON format, and the path specified is the format of the data. For more examples, see Amazon Redshift COPY command examples.
        var copyOptions: String? = nil

        public init() {}

        public init(dataTableName: String, dataTableColumns: String? = nil, copyOptions: String? = nil) {
            self.dataTableName = dataTableName
            self.dataTableColumns = dataTableColumns
            self.copyOptions = copyOptions
        }

    }

    public struct ExtendedS3DestinationConfiguration: Serializable, Initializable {
        /// The ARN of the S3 bucket.
        var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        var prefix: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String = ""
        /// The configuration for backup in Amazon S3.
        var s3BackupConfiguration: S3DestinationConfiguration? = nil
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The Amazon S3 backup mode.
        var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED.
        var compressionFormat: String? = nil
        /// The buffering option.
        var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String, encryptionConfiguration: EncryptionConfiguration? = nil, prefix: String? = nil, roleARN: String, s3BackupConfiguration: S3DestinationConfiguration? = nil, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.s3BackupConfiguration = s3BackupConfiguration
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct ElasticsearchRetryOptions: Serializable, Initializable {
        /// After an initial failure to deliver to Amazon ES, the total amount of time during which Firehose re-attempts delivery (including the first attempt). After this time has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5 minutes). A value of 0 (zero) results in no retries.
        var durationInSeconds: Int32? = nil

        public init() {}

        public init(durationInSeconds: Int32? = nil) {
            self.durationInSeconds = durationInSeconds
        }

    }

    public struct PutRecordOutput: Serializable, Initializable {
        /// The ID of the record.
        var recordId: String = ""

        public init() {}

        public init(recordId: String) {
            self.recordId = recordId
        }

    }

    public struct DestinationDescription: Serializable, Initializable {
        /// [Deprecated] The destination in Amazon S3.
        var s3DestinationDescription: S3DestinationDescription? = nil
        /// The ID of the destination.
        var destinationId: String = ""
        /// The destination in Amazon Redshift.
        var redshiftDestinationDescription: RedshiftDestinationDescription? = nil
        /// The destination in Amazon S3.
        var extendedS3DestinationDescription: ExtendedS3DestinationDescription? = nil
        /// The destination in Amazon ES.
        var elasticsearchDestinationDescription: ElasticsearchDestinationDescription? = nil

        public init() {}

        public init(s3DestinationDescription: S3DestinationDescription? = nil, destinationId: String, redshiftDestinationDescription: RedshiftDestinationDescription? = nil, extendedS3DestinationDescription: ExtendedS3DestinationDescription? = nil, elasticsearchDestinationDescription: ElasticsearchDestinationDescription? = nil) {
            self.s3DestinationDescription = s3DestinationDescription
            self.destinationId = destinationId
            self.redshiftDestinationDescription = redshiftDestinationDescription
            self.extendedS3DestinationDescription = extendedS3DestinationDescription
            self.elasticsearchDestinationDescription = elasticsearchDestinationDescription
        }

    }

    public struct UpdateDestinationInput: Serializable, Initializable {
        /// Describes an update for a destination in Amazon ES.
        var elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate? = nil
        /// The name of the delivery stream.
        var deliveryStreamName: String = ""
        /// Obtain this value from the VersionId result of DeliveryStreamDescription. This value is required, and helps the service to perform conditional operations. For example, if there is a interleaving update and this value is null, then the update destination fails. After the update is successful, the VersionId value is updated. The service then performs a merge of the old configuration with the new configuration.
        var currentDeliveryStreamVersionId: String = ""
        /// The ID of the destination.
        var destinationId: String = ""
        /// Describes an update for a destination in Amazon S3.
        var extendedS3DestinationUpdate: ExtendedS3DestinationUpdate? = nil
        /// Describes an update for a destination in Amazon Redshift.
        var redshiftDestinationUpdate: RedshiftDestinationUpdate? = nil
        /// [Deprecated] Describes an update for a destination in Amazon S3.
        var s3DestinationUpdate: S3DestinationUpdate? = nil

        public init() {}

        public init(elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate? = nil, deliveryStreamName: String, currentDeliveryStreamVersionId: String, destinationId: String, extendedS3DestinationUpdate: ExtendedS3DestinationUpdate? = nil, redshiftDestinationUpdate: RedshiftDestinationUpdate? = nil, s3DestinationUpdate: S3DestinationUpdate? = nil) {
            self.elasticsearchDestinationUpdate = elasticsearchDestinationUpdate
            self.deliveryStreamName = deliveryStreamName
            self.currentDeliveryStreamVersionId = currentDeliveryStreamVersionId
            self.destinationId = destinationId
            self.extendedS3DestinationUpdate = extendedS3DestinationUpdate
            self.redshiftDestinationUpdate = redshiftDestinationUpdate
            self.s3DestinationUpdate = s3DestinationUpdate
        }

    }

    public struct ListDeliveryStreamsOutput: Serializable, Initializable {
        /// The names of the delivery streams.
        var deliveryStreamNames: [String] = []
        /// Indicates whether there are more delivery streams available to list.
        var hasMoreDeliveryStreams: Bool = false

        public init() {}

        public init(deliveryStreamNames: [String], hasMoreDeliveryStreams: Bool) {
            self.deliveryStreamNames = deliveryStreamNames
            self.hasMoreDeliveryStreams = hasMoreDeliveryStreams
        }

    }

    public struct RedshiftDestinationDescription: Serializable, Initializable {
        /// The configuration for backup in Amazon S3.
        var s3BackupDescription: S3DestinationDescription? = nil
        /// The COPY command.
        var copyCommand: CopyCommand = CopyCommand()
        /// The ARN of the AWS credentials.
        var roleARN: String = ""
        /// The Amazon S3 destination.
        var s3DestinationDescription: S3DestinationDescription = S3DestinationDescription()
        /// The name of the user.
        var username: String = ""
        /// The database connection string.
        var clusterJDBCURL: String = ""
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The Amazon S3 backup mode.
        var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).
        var retryOptions: RedshiftRetryOptions? = nil

        public init() {}

        public init(s3BackupDescription: S3DestinationDescription? = nil, copyCommand: CopyCommand, roleARN: String, s3DestinationDescription: S3DestinationDescription, username: String, clusterJDBCURL: String, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: RedshiftRetryOptions? = nil) {
            self.s3BackupDescription = s3BackupDescription
            self.copyCommand = copyCommand
            self.roleARN = roleARN
            self.s3DestinationDescription = s3DestinationDescription
            self.username = username
            self.clusterJDBCURL = clusterJDBCURL
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
        }

    }

    public struct ListDeliveryStreamsInput: Serializable, Initializable {
        /// The maximum number of delivery streams to list.
        var limit: Int32? = nil
        /// The name of the delivery stream to start the list with.
        var exclusiveStartDeliveryStreamName: String? = nil

        public init() {}

        public init(limit: Int32? = nil, exclusiveStartDeliveryStreamName: String? = nil) {
            self.limit = limit
            self.exclusiveStartDeliveryStreamName = exclusiveStartDeliveryStreamName
        }

    }

    public struct S3DestinationConfiguration: Serializable, Initializable {
        /// The ARN of the S3 bucket.
        var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        var prefix: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String = ""
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED. The compression formats SNAPPY or ZIP cannot be specified for Amazon Redshift destinations because they are not supported by the Amazon Redshift COPY operation that reads from the S3 bucket.
        var compressionFormat: String? = nil
        /// The buffering option. If no value is specified, BufferingHints object default values are used.
        var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String, encryptionConfiguration: EncryptionConfiguration? = nil, prefix: String? = nil, roleARN: String, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct S3DestinationDescription: Serializable, Initializable {
        /// The ARN of the S3 bucket.
        var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        var encryptionConfiguration: EncryptionConfiguration = EncryptionConfiguration()
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        var prefix: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String = ""
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED.
        var compressionFormat: String = ""
        /// The buffering option. If no value is specified, BufferingHints object default values are used.
        var bufferingHints: BufferingHints = BufferingHints()

        public init() {}

        public init(bucketARN: String, encryptionConfiguration: EncryptionConfiguration, prefix: String? = nil, roleARN: String, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String, bufferingHints: BufferingHints) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct DeleteDeliveryStreamInput: Serializable, Initializable {
        /// The name of the delivery stream.
        var deliveryStreamName: String = ""

        public init() {}

        public init(deliveryStreamName: String) {
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct UpdateDestinationOutput: Serializable, Initializable {

        public init() {}

    }

    public struct RedshiftDestinationUpdate: Serializable, Initializable {
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The COPY command.
        var copyCommand: CopyCommand? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String? = nil
        /// The name of the user.
        var username: String? = nil
        /// The Amazon S3 destination for backup.
        var s3BackupUpdate: S3DestinationUpdate? = nil
        /// The Amazon S3 backup mode.
        var s3BackupMode: String? = nil
        /// The database connection string.
        var clusterJDBCURL: String? = nil
        /// The Amazon S3 destination. The compression formats SNAPPY or ZIP cannot be specified in RedshiftDestinationUpdate.S3Update because the Amazon Redshift COPY operation that reads from the S3 bucket doesn't support these compression formats.
        var s3Update: S3DestinationUpdate? = nil
        /// The user password.
        var password: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).
        var retryOptions: RedshiftRetryOptions? = nil

        public init() {}

        public init(processingConfiguration: ProcessingConfiguration? = nil, copyCommand: CopyCommand? = nil, roleARN: String? = nil, username: String? = nil, s3BackupUpdate: S3DestinationUpdate? = nil, s3BackupMode: String? = nil, clusterJDBCURL: String? = nil, s3Update: S3DestinationUpdate? = nil, password: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: RedshiftRetryOptions? = nil) {
            self.processingConfiguration = processingConfiguration
            self.copyCommand = copyCommand
            self.roleARN = roleARN
            self.username = username
            self.s3BackupUpdate = s3BackupUpdate
            self.s3BackupMode = s3BackupMode
            self.clusterJDBCURL = clusterJDBCURL
            self.s3Update = s3Update
            self.password = password
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
        }

    }

    public struct BufferingHints: Serializable, Initializable {
        /// Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.
        var intervalInSeconds: Int32? = nil
        /// Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5. We recommend setting this parameter to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB or higher.
        var sizeInMBs: Int32? = nil

        public init() {}

        public init(intervalInSeconds: Int32? = nil, sizeInMBs: Int32? = nil) {
            self.intervalInSeconds = intervalInSeconds
            self.sizeInMBs = sizeInMBs
        }

    }

    public struct RedshiftRetryOptions: Serializable, Initializable {
        /// The length of time during which Firehose retries delivery after a failure, starting from the initial request and including the first attempt. The default value is 3600 seconds (60 minutes). Firehose does not retry if the value of DurationInSeconds is 0 (zero) or if the first delivery attempt takes longer than the current value.
        var durationInSeconds: Int32? = nil

        public init() {}

        public init(durationInSeconds: Int32? = nil) {
            self.durationInSeconds = durationInSeconds
        }

    }

    public struct S3DestinationUpdate: Serializable, Initializable {
        /// The ARN of the S3 bucket.
        var bucketARN: String? = nil
        /// The encryption configuration. If no value is specified, the default is no encryption.
        var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        var prefix: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED. The compression formats SNAPPY or ZIP cannot be specified for Amazon Redshift destinations because they are not supported by the Amazon Redshift COPY operation that reads from the S3 bucket.
        var compressionFormat: String? = nil
        /// The buffering option. If no value is specified, BufferingHints object default values are used.
        var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String? = nil, encryptionConfiguration: EncryptionConfiguration? = nil, prefix: String? = nil, roleARN: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct PutRecordBatchOutput: Serializable, Initializable {
        /// The results array. For each record, the index of the response element is the same as the index used in the request array.
        var requestResponses: [PutRecordBatchResponseEntry] = []
        /// The number of records that might have failed processing.
        var failedPutCount: Int32 = 0

        public init() {}

        public init(requestResponses: [PutRecordBatchResponseEntry], failedPutCount: Int32) {
            self.requestResponses = requestResponses
            self.failedPutCount = failedPutCount
        }

    }

    public struct CreateDeliveryStreamOutput: Serializable, Initializable {
        /// The ARN of the delivery stream.
        var deliveryStreamARN: String? = nil

        public init() {}

        public init(deliveryStreamARN: String? = nil) {
            self.deliveryStreamARN = deliveryStreamARN
        }

    }

    public struct ElasticsearchDestinationUpdate: Serializable, Initializable {
        /// The Elasticsearch type name.
        var typeName: String? = nil
        /// The Elasticsearch index name.
        var indexName: String? = nil
        /// The Elasticsearch index rotation period. Index rotation appends a timestamp to IndexName to facilitate the expiration of old data. For more information, see Index Rotation for Amazon Elasticsearch Service Destination. Default value is OneDay.
        var indexRotationPeriod: String? = nil
        /// The ARN of the Amazon ES domain. The IAM role must have permissions for DescribeElasticsearchDomain, DescribeElasticsearchDomains, and DescribeElasticsearchDomainConfig after assuming the IAM role specified in RoleARN.
        var domainARN: String? = nil
        /// The ARN of the IAM role to be assumed by Firehose for calling the Amazon ES Configuration API and for indexing documents. For more information, see Amazon S3 Bucket Access.
        var roleARN: String? = nil
        /// The Amazon S3 destination.
        var s3Update: S3DestinationUpdate? = nil
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon ES. Default value is 300 (5 minutes).
        var retryOptions: ElasticsearchRetryOptions? = nil
        /// The buffering options. If no value is specified, ElasticsearchBufferingHints object default values are used. 
        var bufferingHints: ElasticsearchBufferingHints? = nil

        public init() {}

        public init(typeName: String? = nil, indexName: String? = nil, indexRotationPeriod: String? = nil, domainARN: String? = nil, roleARN: String? = nil, s3Update: S3DestinationUpdate? = nil, processingConfiguration: ProcessingConfiguration? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: ElasticsearchRetryOptions? = nil, bufferingHints: ElasticsearchBufferingHints? = nil) {
            self.typeName = typeName
            self.indexName = indexName
            self.indexRotationPeriod = indexRotationPeriod
            self.domainARN = domainARN
            self.roleARN = roleARN
            self.s3Update = s3Update
            self.processingConfiguration = processingConfiguration
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.bufferingHints = bufferingHints
        }

    }

    public struct CreateDeliveryStreamInput: Serializable, Initializable {
        /// The destination in Amazon ES. You can specify only one destination.
        var elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration? = nil
        /// The destination in Amazon S3. You can specify only one destination.
        var extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration? = nil
        /// [Deprecated] The destination in Amazon S3. You can specify only one destination.
        var s3DestinationConfiguration: S3DestinationConfiguration? = nil
        /// The destination in Amazon Redshift. You can specify only one destination.
        var redshiftDestinationConfiguration: RedshiftDestinationConfiguration? = nil
        /// The name of the delivery stream. This name must be unique per AWS account in the same region. You can have multiple delivery streams with the same name if they are in different accounts or different regions.
        var deliveryStreamName: String = ""

        public init() {}

        public init(elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration? = nil, extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration? = nil, s3DestinationConfiguration: S3DestinationConfiguration? = nil, redshiftDestinationConfiguration: RedshiftDestinationConfiguration? = nil, deliveryStreamName: String) {
            self.elasticsearchDestinationConfiguration = elasticsearchDestinationConfiguration
            self.extendedS3DestinationConfiguration = extendedS3DestinationConfiguration
            self.s3DestinationConfiguration = s3DestinationConfiguration
            self.redshiftDestinationConfiguration = redshiftDestinationConfiguration
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct ElasticsearchDestinationConfiguration: Serializable, Initializable {
        /// The Elasticsearch type name.
        var typeName: String = ""
        /// The Elasticsearch index name.
        var indexName: String = ""
        /// The configuration for the intermediate Amazon S3 location from which Amazon ES obtains data.
        var s3Configuration: S3DestinationConfiguration = S3DestinationConfiguration()
        /// The Elasticsearch index rotation period. Index rotation appends a timestamp to the IndexName to facilitate expiration of old data. For more information, see Index Rotation for Amazon Elasticsearch Service Destination. The default value is OneDay.
        var indexRotationPeriod: String? = nil
        /// The ARN of the Amazon ES domain. The IAM role must have permissions for DescribeElasticsearchDomain, DescribeElasticsearchDomains, and DescribeElasticsearchDomainConfig after assuming the role specified in RoleARN.
        var domainARN: String = ""
        /// The ARN of the IAM role to be assumed by Firehose for calling the Amazon ES Configuration API and for indexing documents. For more information, see Amazon S3 Bucket Access.
        var roleARN: String = ""
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// Defines how documents should be delivered to Amazon S3. When set to FailedDocumentsOnly, Firehose writes any documents that could not be indexed to the configured Amazon S3 destination, with elasticsearch-failed/ appended to the key prefix. When set to AllDocuments, Firehose delivers all incoming records to Amazon S3, and also writes failed documents with elasticsearch-failed/ appended to the prefix. For more information, see Amazon S3 Backup for Amazon Elasticsearch Service Destination. Default value is FailedDocumentsOnly.
        var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon ES. The default value is 300 (5 minutes).
        var retryOptions: ElasticsearchRetryOptions? = nil
        /// The buffering options. If no value is specified, the default values for ElasticsearchBufferingHints are used.
        var bufferingHints: ElasticsearchBufferingHints? = nil

        public init() {}

        public init(typeName: String, indexName: String, s3Configuration: S3DestinationConfiguration, indexRotationPeriod: String? = nil, domainARN: String, roleARN: String, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: ElasticsearchRetryOptions? = nil, bufferingHints: ElasticsearchBufferingHints? = nil) {
            self.typeName = typeName
            self.indexName = indexName
            self.s3Configuration = s3Configuration
            self.indexRotationPeriod = indexRotationPeriod
            self.domainARN = domainARN
            self.roleARN = roleARN
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.bufferingHints = bufferingHints
        }

    }

    public struct Record: Serializable, Initializable {
        /// The data blob, which is base64-encoded when the blob is serialized. The maximum size of the data blob, before base64-encoding, is 1,000 KB.
        var data: Data = Data()

        public init() {}

        public init(data: Data) {
            self.data = data
        }

    }

    public struct PutRecordBatchInput: Serializable, Initializable {
        /// One or more records.
        var records: [Record] = []
        /// The name of the delivery stream.
        var deliveryStreamName: String = ""

        public init() {}

        public init(records: [Record], deliveryStreamName: String) {
            self.records = records
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct ProcessorParameter: Serializable, Initializable {
        /// The name of the parameter.
        var parameterName: String = ""
        /// The parameter value.
        var parameterValue: String = ""

        public init() {}

        public init(parameterName: String, parameterValue: String) {
            self.parameterName = parameterName
            self.parameterValue = parameterValue
        }

    }

    public struct KMSEncryptionConfig: Serializable, Initializable {
        /// The ARN of the encryption key. Must belong to the same region as the destination Amazon S3 bucket.
        var aWSKMSKeyARN: String = ""

        public init() {}

        public init(aWSKMSKeyARN: String) {
            self.aWSKMSKeyARN = aWSKMSKeyARN
        }

    }

    public struct ExtendedS3DestinationDescription: Serializable, Initializable {
        /// The configuration for backup in Amazon S3.
        var s3BackupDescription: S3DestinationDescription? = nil
        /// The ARN of the S3 bucket.
        var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        var encryptionConfiguration: EncryptionConfiguration = EncryptionConfiguration()
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        var prefix: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String = ""
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The Amazon S3 backup mode.
        var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED.
        var compressionFormat: String = ""
        /// The buffering option.
        var bufferingHints: BufferingHints = BufferingHints()

        public init() {}

        public init(s3BackupDescription: S3DestinationDescription? = nil, bucketARN: String, encryptionConfiguration: EncryptionConfiguration, prefix: String? = nil, roleARN: String, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String, bufferingHints: BufferingHints) {
            self.s3BackupDescription = s3BackupDescription
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct PutRecordInput: Serializable, Initializable {
        /// The record.
        var record: Record = Record()
        /// The name of the delivery stream.
        var deliveryStreamName: String = ""

        public init() {}

        public init(record: Record, deliveryStreamName: String) {
            self.record = record
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct DeleteDeliveryStreamOutput: Serializable, Initializable {

        public init() {}

    }

    public struct Processor: Serializable, Initializable {
        /// The type of processor.
        var type: String = ""
        /// The processor parameters.
        var parameters: [ProcessorParameter]? = nil

        public init() {}

        public init(type: String, parameters: [ProcessorParameter]? = nil) {
            self.type = type
            self.parameters = parameters
        }

    }

    public struct ExtendedS3DestinationUpdate: Serializable, Initializable {
        /// The ARN of the S3 bucket.
        var bucketARN: String? = nil
        /// The encryption configuration. If no value is specified, the default is no encryption.
        var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        var prefix: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String? = nil
        /// The Amazon S3 destination for backup.
        var s3BackupUpdate: S3DestinationUpdate? = nil
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// Enables or disables Amazon S3 backup mode.
        var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED. 
        var compressionFormat: String? = nil
        /// The buffering option.
        var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String? = nil, encryptionConfiguration: EncryptionConfiguration? = nil, prefix: String? = nil, roleARN: String? = nil, s3BackupUpdate: S3DestinationUpdate? = nil, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.s3BackupUpdate = s3BackupUpdate
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct CloudWatchLoggingOptions: Serializable, Initializable {
        /// The CloudWatch log stream name for logging. This value is required if CloudWatch logging is enabled.
        var logStreamName: String? = nil
        /// The CloudWatch group name for logging. This value is required if CloudWatch logging is enabled.
        var logGroupName: String? = nil
        /// Enables or disables CloudWatch logging.
        var enabled: Bool? = nil

        public init() {}

        public init(logStreamName: String? = nil, logGroupName: String? = nil, enabled: Bool? = nil) {
            self.logStreamName = logStreamName
            self.logGroupName = logGroupName
            self.enabled = enabled
        }

    }

    public struct DescribeDeliveryStreamInput: Serializable, Initializable {
        /// The ID of the destination to start returning the destination information. Currently Firehose supports one destination per delivery stream.
        var exclusiveStartDestinationId: String? = nil
        /// The limit on the number of destinations to return. Currently, you can have one destination per delivery stream.
        var limit: Int32? = nil
        /// The name of the delivery stream.
        var deliveryStreamName: String = ""

        public init() {}

        public init(exclusiveStartDestinationId: String? = nil, limit: Int32? = nil, deliveryStreamName: String) {
            self.exclusiveStartDestinationId = exclusiveStartDestinationId
            self.limit = limit
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct EncryptionConfiguration: Serializable, Initializable {
        /// The encryption key.
        var kMSEncryptionConfig: KMSEncryptionConfig? = nil
        /// Specifically override existing encryption information to ensure no encryption is used.
        var noEncryptionConfig: String? = nil

        public init() {}

        public init(kMSEncryptionConfig: KMSEncryptionConfig? = nil, noEncryptionConfig: String? = nil) {
            self.kMSEncryptionConfig = kMSEncryptionConfig
            self.noEncryptionConfig = noEncryptionConfig
        }

    }

    public struct DeliveryStreamDescription: Serializable, Initializable {
        /// The destinations.
        var destinations: [DestinationDescription] = []
        /// The status of the delivery stream.
        var deliveryStreamStatus: String = ""
        /// The date and time that the delivery stream was last updated.
        var lastUpdateTimestamp: Date? = nil
        /// The name of the delivery stream.
        var deliveryStreamName: String = ""
        /// Each time the destination is updated for a delivery stream, the version ID is changed, and the current version ID is required when updating the destination. This is so that the service knows it is applying the changes to the correct version of the delivery stream.
        var versionId: String = ""
        /// The date and time that the delivery stream was created.
        var createTimestamp: Date? = nil
        /// The Amazon Resource Name (ARN) of the delivery stream.
        var deliveryStreamARN: String = ""
        /// Indicates whether there are more destinations available to list.
        var hasMoreDestinations: Bool = false

        public init() {}

        public init(destinations: [DestinationDescription], deliveryStreamStatus: String, lastUpdateTimestamp: Date? = nil, deliveryStreamName: String, versionId: String, createTimestamp: Date? = nil, deliveryStreamARN: String, hasMoreDestinations: Bool) {
            self.destinations = destinations
            self.deliveryStreamStatus = deliveryStreamStatus
            self.lastUpdateTimestamp = lastUpdateTimestamp
            self.deliveryStreamName = deliveryStreamName
            self.versionId = versionId
            self.createTimestamp = createTimestamp
            self.deliveryStreamARN = deliveryStreamARN
            self.hasMoreDestinations = hasMoreDestinations
        }

    }

    public struct ElasticsearchDestinationDescription: Serializable, Initializable {
        /// The Elasticsearch type name.
        var typeName: String? = nil
        /// The Elasticsearch index name.
        var indexName: String? = nil
        /// The Elasticsearch index rotation period
        var indexRotationPeriod: String? = nil
        /// The ARN of the Amazon ES domain.
        var domainARN: String? = nil
        /// The ARN of the AWS credentials.
        var roleARN: String? = nil
        /// The Amazon S3 destination.
        var s3DestinationDescription: S3DestinationDescription? = nil
        /// The data processing configuration.
        var processingConfiguration: ProcessingConfiguration? = nil
        /// The Amazon S3 backup mode.
        var s3BackupMode: String? = nil
        /// The CloudWatch logging options.
        var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The Amazon ES retry options.
        var retryOptions: ElasticsearchRetryOptions? = nil
        /// The buffering options.
        var bufferingHints: ElasticsearchBufferingHints? = nil

        public init() {}

        public init(typeName: String? = nil, indexName: String? = nil, indexRotationPeriod: String? = nil, domainARN: String? = nil, roleARN: String? = nil, s3DestinationDescription: S3DestinationDescription? = nil, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: ElasticsearchRetryOptions? = nil, bufferingHints: ElasticsearchBufferingHints? = nil) {
            self.typeName = typeName
            self.indexName = indexName
            self.indexRotationPeriod = indexRotationPeriod
            self.domainARN = domainARN
            self.roleARN = roleARN
            self.s3DestinationDescription = s3DestinationDescription
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.bufferingHints = bufferingHints
        }

    }

    public struct ElasticsearchBufferingHints: Serializable, Initializable {
        /// Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5. We recommend setting this parameter to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB or higher.
        var sizeInMBs: Int32? = nil
        /// Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300 (5 minutes).
        var intervalInSeconds: Int32? = nil

        public init() {}

        public init(sizeInMBs: Int32? = nil, intervalInSeconds: Int32? = nil) {
            self.sizeInMBs = sizeInMBs
            self.intervalInSeconds = intervalInSeconds
        }

    }

    public struct PutRecordBatchResponseEntry: Serializable, Initializable {
        /// The ID of the record.
        var recordId: String? = nil
        /// The error code for an individual record result.
        var errorCode: String? = nil
        /// The error message for an individual record result.
        var errorMessage: String? = nil

        public init() {}

        public init(recordId: String? = nil, errorCode: String? = nil, errorMessage: String? = nil) {
            self.recordId = recordId
            self.errorCode = errorCode
            self.errorMessage = errorMessage
        }

    }

}