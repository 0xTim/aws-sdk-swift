// THIS FILE IS AUTOMATICALLY GENERATED. DO NOT EDIT.
/**
The MIT License (MIT)

Copyright (c) 2017 Yuki Takei(noppoMan)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

*/

import Foundation
import Core

extension Firehose {

    public struct DescribeDeliveryStreamOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// Information about the delivery stream.
        public var deliveryStreamDescription: DeliveryStreamDescription = DeliveryStreamDescription()

        public init() {}

        public init(deliveryStreamDescription: DeliveryStreamDescription) {
            self.deliveryStreamDescription = deliveryStreamDescription
        }

    }

    public struct ProcessingConfiguration: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The data processors.
        public var processors: [Processor]? = nil
        /// Enables or disables data processing.
        public var enabled: Bool? = nil

        public init() {}

        public init(processors: [Processor]? = nil, enabled: Bool? = nil) {
            self.processors = processors
            self.enabled = enabled
        }

    }

    public struct RedshiftDestinationConfiguration: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The COPY command.
        public var copyCommand: CopyCommand = CopyCommand()
        /// The configuration for the intermediate Amazon S3 location from which Amazon Redshift obtains data. Restrictions are described in the topic for CreateDeliveryStream. The compression formats SNAPPY or ZIP cannot be specified in RedshiftDestinationConfiguration.S3Configuration because the Amazon Redshift COPY operation that reads from the S3 bucket doesn't support these compression formats.
        public var s3Configuration: S3DestinationConfiguration = S3DestinationConfiguration()
        /// The name of the user.
        public var username: String = ""
        /// The configuration for backup in Amazon S3.
        public var s3BackupConfiguration: S3DestinationConfiguration? = nil
        /// The database connection string.
        public var clusterJDBCURL: String = ""
        /// The ARN of the AWS credentials.
        public var roleARN: String = ""
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The user password.
        public var password: String = ""
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).
        public var retryOptions: RedshiftRetryOptions? = nil
        /// The Amazon S3 backup mode.
        public var s3BackupMode: String? = nil

        public init() {}

        public init(copyCommand: CopyCommand, s3Configuration: S3DestinationConfiguration, username: String, s3BackupConfiguration: S3DestinationConfiguration? = nil, clusterJDBCURL: String, roleARN: String, processingConfiguration: ProcessingConfiguration? = nil, password: String, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: RedshiftRetryOptions? = nil, s3BackupMode: String? = nil) {
            self.copyCommand = copyCommand
            self.s3Configuration = s3Configuration
            self.username = username
            self.s3BackupConfiguration = s3BackupConfiguration
            self.clusterJDBCURL = clusterJDBCURL
            self.roleARN = roleARN
            self.processingConfiguration = processingConfiguration
            self.password = password
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.s3BackupMode = s3BackupMode
        }

    }

    public struct CopyCommand: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The name of the target table. The table must already exist in the database.
        public var dataTableName: String = ""
        /// A comma-separated list of column names.
        public var dataTableColumns: String? = nil
        /// Optional parameters to use with the Amazon Redshift COPY command. For more information, see the "Optional Parameters" section of Amazon Redshift COPY command. Some possible examples that would apply to Firehose are as follows:  delimiter '\t' lzop; - fields are delimited with "\t" (TAB character) and compressed using lzop.  delimiter '| - fields are delimited with "|" (this is the default delimiter).  delimiter '|' escape - the delimiter should be escaped.  fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6' - fields are fixed width in the source, with each width specified after every column in the table.  JSON 's3://mybucket/jsonpaths.txt' - data is in JSON format, and the path specified is the format of the data. For more examples, see Amazon Redshift COPY command examples.
        public var copyOptions: String? = nil

        public init() {}

        public init(dataTableName: String, dataTableColumns: String? = nil, copyOptions: String? = nil) {
            self.dataTableName = dataTableName
            self.dataTableColumns = dataTableColumns
            self.copyOptions = copyOptions
        }

    }

    public struct ExtendedS3DestinationConfiguration: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the S3 bucket.
        public var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        public var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String = ""
        /// The configuration for backup in Amazon S3.
        public var s3BackupConfiguration: S3DestinationConfiguration? = nil
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        public var prefix: String? = nil
        /// The Amazon S3 backup mode.
        public var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED.
        public var compressionFormat: String? = nil
        /// The buffering option.
        public var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String, encryptionConfiguration: EncryptionConfiguration? = nil, roleARN: String, s3BackupConfiguration: S3DestinationConfiguration? = nil, processingConfiguration: ProcessingConfiguration? = nil, prefix: String? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.roleARN = roleARN
            self.s3BackupConfiguration = s3BackupConfiguration
            self.processingConfiguration = processingConfiguration
            self.prefix = prefix
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct ElasticsearchRetryOptions: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// After an initial failure to deliver to Amazon ES, the total amount of time during which Firehose re-attempts delivery (including the first attempt). After this time has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5 minutes). A value of 0 (zero) results in no retries.
        public var durationInSeconds: Int32? = nil

        public init() {}

        public init(durationInSeconds: Int32? = nil) {
            self.durationInSeconds = durationInSeconds
        }

    }

    public struct PutRecordOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ID of the record.
        public var recordId: String = ""

        public init() {}

        public init(recordId: String) {
            self.recordId = recordId
        }

    }

    public struct DestinationDescription: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// [Deprecated] The destination in Amazon S3.
        public var s3DestinationDescription: S3DestinationDescription? = nil
        /// The ID of the destination.
        public var destinationId: String = ""
        /// The destination in Amazon Redshift.
        public var redshiftDestinationDescription: RedshiftDestinationDescription? = nil
        /// The destination in Amazon S3.
        public var extendedS3DestinationDescription: ExtendedS3DestinationDescription? = nil
        /// The destination in Amazon ES.
        public var elasticsearchDestinationDescription: ElasticsearchDestinationDescription? = nil

        public init() {}

        public init(s3DestinationDescription: S3DestinationDescription? = nil, destinationId: String, redshiftDestinationDescription: RedshiftDestinationDescription? = nil, extendedS3DestinationDescription: ExtendedS3DestinationDescription? = nil, elasticsearchDestinationDescription: ElasticsearchDestinationDescription? = nil) {
            self.s3DestinationDescription = s3DestinationDescription
            self.destinationId = destinationId
            self.redshiftDestinationDescription = redshiftDestinationDescription
            self.extendedS3DestinationDescription = extendedS3DestinationDescription
            self.elasticsearchDestinationDescription = elasticsearchDestinationDescription
        }

    }

    public struct UpdateDestinationInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// Describes an update for a destination in Amazon ES.
        public var elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate? = nil
        /// The name of the delivery stream.
        public var deliveryStreamName: String = ""
        /// Obtain this value from the VersionId result of DeliveryStreamDescription. This value is required, and helps the service to perform conditional operations. For example, if there is a interleaving update and this value is null, then the update destination fails. After the update is successful, the VersionId value is updated. The service then performs a merge of the old configuration with the new configuration.
        public var currentDeliveryStreamVersionId: String = ""
        /// The ID of the destination.
        public var destinationId: String = ""
        /// Describes an update for a destination in Amazon S3.
        public var extendedS3DestinationUpdate: ExtendedS3DestinationUpdate? = nil
        /// Describes an update for a destination in Amazon Redshift.
        public var redshiftDestinationUpdate: RedshiftDestinationUpdate? = nil
        /// [Deprecated] Describes an update for a destination in Amazon S3.
        public var s3DestinationUpdate: S3DestinationUpdate? = nil

        public init() {}

        public init(elasticsearchDestinationUpdate: ElasticsearchDestinationUpdate? = nil, deliveryStreamName: String, currentDeliveryStreamVersionId: String, destinationId: String, extendedS3DestinationUpdate: ExtendedS3DestinationUpdate? = nil, redshiftDestinationUpdate: RedshiftDestinationUpdate? = nil, s3DestinationUpdate: S3DestinationUpdate? = nil) {
            self.elasticsearchDestinationUpdate = elasticsearchDestinationUpdate
            self.deliveryStreamName = deliveryStreamName
            self.currentDeliveryStreamVersionId = currentDeliveryStreamVersionId
            self.destinationId = destinationId
            self.extendedS3DestinationUpdate = extendedS3DestinationUpdate
            self.redshiftDestinationUpdate = redshiftDestinationUpdate
            self.s3DestinationUpdate = s3DestinationUpdate
        }

    }

    public struct ListDeliveryStreamsOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The names of the delivery streams.
        public var deliveryStreamNames: [String] = []
        /// Indicates whether there are more delivery streams available to list.
        public var hasMoreDeliveryStreams: Bool = false

        public init() {}

        public init(deliveryStreamNames: [String], hasMoreDeliveryStreams: Bool) {
            self.deliveryStreamNames = deliveryStreamNames
            self.hasMoreDeliveryStreams = hasMoreDeliveryStreams
        }

    }

    public struct RedshiftDestinationDescription: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The configuration for backup in Amazon S3.
        public var s3BackupDescription: S3DestinationDescription? = nil
        /// The COPY command.
        public var copyCommand: CopyCommand = CopyCommand()
        /// The name of the user.
        public var username: String = ""
        /// The Amazon S3 destination.
        public var s3DestinationDescription: S3DestinationDescription = S3DestinationDescription()
        /// The database connection string.
        public var clusterJDBCURL: String = ""
        /// The ARN of the AWS credentials.
        public var roleARN: String = ""
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The Amazon S3 backup mode.
        public var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).
        public var retryOptions: RedshiftRetryOptions? = nil

        public init() {}

        public init(s3BackupDescription: S3DestinationDescription? = nil, copyCommand: CopyCommand, username: String, s3DestinationDescription: S3DestinationDescription, clusterJDBCURL: String, roleARN: String, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: RedshiftRetryOptions? = nil) {
            self.s3BackupDescription = s3BackupDescription
            self.copyCommand = copyCommand
            self.username = username
            self.s3DestinationDescription = s3DestinationDescription
            self.clusterJDBCURL = clusterJDBCURL
            self.roleARN = roleARN
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
        }

    }

    public struct ListDeliveryStreamsInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The maximum number of delivery streams to list.
        public var limit: Int32? = nil
        /// The name of the delivery stream to start the list with.
        public var exclusiveStartDeliveryStreamName: String? = nil

        public init() {}

        public init(limit: Int32? = nil, exclusiveStartDeliveryStreamName: String? = nil) {
            self.limit = limit
            self.exclusiveStartDeliveryStreamName = exclusiveStartDeliveryStreamName
        }

    }

    public struct S3DestinationConfiguration: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the S3 bucket.
        public var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        public var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        public var prefix: String? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String = ""
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED. The compression formats SNAPPY or ZIP cannot be specified for Amazon Redshift destinations because they are not supported by the Amazon Redshift COPY operation that reads from the S3 bucket.
        public var compressionFormat: String? = nil
        /// The buffering option. If no value is specified, BufferingHints object default values are used.
        public var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String, encryptionConfiguration: EncryptionConfiguration? = nil, prefix: String? = nil, roleARN: String, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct S3DestinationDescription: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the S3 bucket.
        public var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        public var encryptionConfiguration: EncryptionConfiguration = EncryptionConfiguration()
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        public var prefix: String? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String = ""
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED.
        public var compressionFormat: String = ""
        /// The buffering option. If no value is specified, BufferingHints object default values are used.
        public var bufferingHints: BufferingHints = BufferingHints()

        public init() {}

        public init(bucketARN: String, encryptionConfiguration: EncryptionConfiguration, prefix: String? = nil, roleARN: String, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String, bufferingHints: BufferingHints) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct DeleteDeliveryStreamInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The name of the delivery stream.
        public var deliveryStreamName: String = ""

        public init() {}

        public init(deliveryStreamName: String) {
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct UpdateDestinationOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil

        public init() {}

    }

    public struct RedshiftDestinationUpdate: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The COPY command.
        public var copyCommand: CopyCommand? = nil
        /// The name of the user.
        public var username: String? = nil
        /// The Amazon S3 destination for backup.
        public var s3BackupUpdate: S3DestinationUpdate? = nil
        /// The database connection string.
        public var clusterJDBCURL: String? = nil
        /// The Amazon S3 backup mode.
        public var s3BackupMode: String? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String? = nil
        /// The Amazon S3 destination. The compression formats SNAPPY or ZIP cannot be specified in RedshiftDestinationUpdate.S3Update because the Amazon Redshift COPY operation that reads from the S3 bucket doesn't support these compression formats.
        public var s3Update: S3DestinationUpdate? = nil
        /// The user password.
        public var password: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon Redshift. Default value is 3600 (60 minutes).
        public var retryOptions: RedshiftRetryOptions? = nil

        public init() {}

        public init(processingConfiguration: ProcessingConfiguration? = nil, copyCommand: CopyCommand? = nil, username: String? = nil, s3BackupUpdate: S3DestinationUpdate? = nil, clusterJDBCURL: String? = nil, s3BackupMode: String? = nil, roleARN: String? = nil, s3Update: S3DestinationUpdate? = nil, password: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: RedshiftRetryOptions? = nil) {
            self.processingConfiguration = processingConfiguration
            self.copyCommand = copyCommand
            self.username = username
            self.s3BackupUpdate = s3BackupUpdate
            self.clusterJDBCURL = clusterJDBCURL
            self.s3BackupMode = s3BackupMode
            self.roleARN = roleARN
            self.s3Update = s3Update
            self.password = password
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
        }

    }

    public struct BufferingHints: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300.
        public var intervalInSeconds: Int32? = nil
        /// Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5. We recommend setting this parameter to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB or higher.
        public var sizeInMBs: Int32? = nil

        public init() {}

        public init(intervalInSeconds: Int32? = nil, sizeInMBs: Int32? = nil) {
            self.intervalInSeconds = intervalInSeconds
            self.sizeInMBs = sizeInMBs
        }

    }

    public struct RedshiftRetryOptions: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The length of time during which Firehose retries delivery after a failure, starting from the initial request and including the first attempt. The default value is 3600 seconds (60 minutes). Firehose does not retry if the value of DurationInSeconds is 0 (zero) or if the first delivery attempt takes longer than the current value.
        public var durationInSeconds: Int32? = nil

        public init() {}

        public init(durationInSeconds: Int32? = nil) {
            self.durationInSeconds = durationInSeconds
        }

    }

    public struct S3DestinationUpdate: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the S3 bucket.
        public var bucketARN: String? = nil
        /// The encryption configuration. If no value is specified, the default is no encryption.
        public var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        public var prefix: String? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED. The compression formats SNAPPY or ZIP cannot be specified for Amazon Redshift destinations because they are not supported by the Amazon Redshift COPY operation that reads from the S3 bucket.
        public var compressionFormat: String? = nil
        /// The buffering option. If no value is specified, BufferingHints object default values are used.
        public var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String? = nil, encryptionConfiguration: EncryptionConfiguration? = nil, prefix: String? = nil, roleARN: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.prefix = prefix
            self.roleARN = roleARN
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct PutRecordBatchOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The results array. For each record, the index of the response element is the same as the index used in the request array.
        public var requestResponses: [PutRecordBatchResponseEntry] = []
        /// The number of records that might have failed processing.
        public var failedPutCount: Int32 = 0

        public init() {}

        public init(requestResponses: [PutRecordBatchResponseEntry], failedPutCount: Int32) {
            self.requestResponses = requestResponses
            self.failedPutCount = failedPutCount
        }

    }

    public struct CreateDeliveryStreamOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the delivery stream.
        public var deliveryStreamARN: String? = nil

        public init() {}

        public init(deliveryStreamARN: String? = nil) {
            self.deliveryStreamARN = deliveryStreamARN
        }

    }

    public struct ElasticsearchDestinationUpdate: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The Elasticsearch type name.
        public var typeName: String? = nil
        /// The Elasticsearch index name.
        public var indexName: String? = nil
        /// The Elasticsearch index rotation period. Index rotation appends a timestamp to IndexName to facilitate the expiration of old data. For more information, see Index Rotation for Amazon Elasticsearch Service Destination. Default value is OneDay.
        public var indexRotationPeriod: String? = nil
        /// The ARN of the Amazon ES domain. The IAM role must have permissions for DescribeElasticsearchDomain, DescribeElasticsearchDomains, and DescribeElasticsearchDomainConfig after assuming the IAM role specified in RoleARN.
        public var domainARN: String? = nil
        /// The ARN of the IAM role to be assumed by Firehose for calling the Amazon ES Configuration API and for indexing documents. For more information, see Amazon S3 Bucket Access.
        public var roleARN: String? = nil
        /// The Amazon S3 destination.
        public var s3Update: S3DestinationUpdate? = nil
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon ES. Default value is 300 (5 minutes).
        public var retryOptions: ElasticsearchRetryOptions? = nil
        /// The buffering options. If no value is specified, ElasticsearchBufferingHints object default values are used. 
        public var bufferingHints: ElasticsearchBufferingHints? = nil

        public init() {}

        public init(typeName: String? = nil, indexName: String? = nil, indexRotationPeriod: String? = nil, domainARN: String? = nil, roleARN: String? = nil, s3Update: S3DestinationUpdate? = nil, processingConfiguration: ProcessingConfiguration? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: ElasticsearchRetryOptions? = nil, bufferingHints: ElasticsearchBufferingHints? = nil) {
            self.typeName = typeName
            self.indexName = indexName
            self.indexRotationPeriod = indexRotationPeriod
            self.domainARN = domainARN
            self.roleARN = roleARN
            self.s3Update = s3Update
            self.processingConfiguration = processingConfiguration
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.bufferingHints = bufferingHints
        }

    }

    public struct CreateDeliveryStreamInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The destination in Amazon ES. You can specify only one destination.
        public var elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration? = nil
        /// The destination in Amazon S3. You can specify only one destination.
        public var extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration? = nil
        /// [Deprecated] The destination in Amazon S3. You can specify only one destination.
        public var s3DestinationConfiguration: S3DestinationConfiguration? = nil
        /// The destination in Amazon Redshift. You can specify only one destination.
        public var redshiftDestinationConfiguration: RedshiftDestinationConfiguration? = nil
        /// The name of the delivery stream. This name must be unique per AWS account in the same region. You can have multiple delivery streams with the same name if they are in different accounts or different regions.
        public var deliveryStreamName: String = ""

        public init() {}

        public init(elasticsearchDestinationConfiguration: ElasticsearchDestinationConfiguration? = nil, extendedS3DestinationConfiguration: ExtendedS3DestinationConfiguration? = nil, s3DestinationConfiguration: S3DestinationConfiguration? = nil, redshiftDestinationConfiguration: RedshiftDestinationConfiguration? = nil, deliveryStreamName: String) {
            self.elasticsearchDestinationConfiguration = elasticsearchDestinationConfiguration
            self.extendedS3DestinationConfiguration = extendedS3DestinationConfiguration
            self.s3DestinationConfiguration = s3DestinationConfiguration
            self.redshiftDestinationConfiguration = redshiftDestinationConfiguration
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct ElasticsearchDestinationConfiguration: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The Elasticsearch type name.
        public var typeName: String = ""
        /// The Elasticsearch index name.
        public var indexName: String = ""
        /// The configuration for the intermediate Amazon S3 location from which Amazon ES obtains data.
        public var s3Configuration: S3DestinationConfiguration = S3DestinationConfiguration()
        /// The Elasticsearch index rotation period. Index rotation appends a timestamp to the IndexName to facilitate expiration of old data. For more information, see Index Rotation for Amazon Elasticsearch Service Destination. The default value is OneDay.
        public var indexRotationPeriod: String? = nil
        /// The ARN of the Amazon ES domain. The IAM role must have permissions for DescribeElasticsearchDomain, DescribeElasticsearchDomains, and DescribeElasticsearchDomainConfig after assuming the role specified in RoleARN.
        public var domainARN: String = ""
        /// The ARN of the IAM role to be assumed by Firehose for calling the Amazon ES Configuration API and for indexing documents. For more information, see Amazon S3 Bucket Access.
        public var roleARN: String = ""
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// Defines how documents should be delivered to Amazon S3. When set to FailedDocumentsOnly, Firehose writes any documents that could not be indexed to the configured Amazon S3 destination, with elasticsearch-failed/ appended to the key prefix. When set to AllDocuments, Firehose delivers all incoming records to Amazon S3, and also writes failed documents with elasticsearch-failed/ appended to the prefix. For more information, see Amazon S3 Backup for Amazon Elasticsearch Service Destination. Default value is FailedDocumentsOnly.
        public var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The retry behavior in the event that Firehose is unable to deliver documents to Amazon ES. The default value is 300 (5 minutes).
        public var retryOptions: ElasticsearchRetryOptions? = nil
        /// The buffering options. If no value is specified, the default values for ElasticsearchBufferingHints are used.
        public var bufferingHints: ElasticsearchBufferingHints? = nil

        public init() {}

        public init(typeName: String, indexName: String, s3Configuration: S3DestinationConfiguration, indexRotationPeriod: String? = nil, domainARN: String, roleARN: String, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: ElasticsearchRetryOptions? = nil, bufferingHints: ElasticsearchBufferingHints? = nil) {
            self.typeName = typeName
            self.indexName = indexName
            self.s3Configuration = s3Configuration
            self.indexRotationPeriod = indexRotationPeriod
            self.domainARN = domainARN
            self.roleARN = roleARN
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.bufferingHints = bufferingHints
        }

    }

    public struct Record: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The data blob, which is base64-encoded when the blob is serialized. The maximum size of the data blob, before base64-encoding, is 1,000 KB.
        public var data: Data = Data()

        public init() {}

        public init(data: Data) {
            self.data = data
        }

    }

    public struct PutRecordBatchInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// One or more records.
        public var records: [Record] = []
        /// The name of the delivery stream.
        public var deliveryStreamName: String = ""

        public init() {}

        public init(records: [Record], deliveryStreamName: String) {
            self.records = records
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct ProcessorParameter: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The name of the parameter.
        public var parameterName: String = ""
        /// The parameter value.
        public var parameterValue: String = ""

        public init() {}

        public init(parameterName: String, parameterValue: String) {
            self.parameterName = parameterName
            self.parameterValue = parameterValue
        }

    }

    public struct KMSEncryptionConfig: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the encryption key. Must belong to the same region as the destination Amazon S3 bucket.
        public var aWSKMSKeyARN: String = ""

        public init() {}

        public init(aWSKMSKeyARN: String) {
            self.aWSKMSKeyARN = aWSKMSKeyARN
        }

    }

    public struct ExtendedS3DestinationDescription: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The configuration for backup in Amazon S3.
        public var s3BackupDescription: S3DestinationDescription? = nil
        /// The ARN of the S3 bucket.
        public var bucketARN: String = ""
        /// The encryption configuration. If no value is specified, the default is no encryption.
        public var encryptionConfiguration: EncryptionConfiguration = EncryptionConfiguration()
        /// The ARN of the AWS credentials.
        public var roleARN: String = ""
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        public var prefix: String? = nil
        /// The Amazon S3 backup mode.
        public var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED.
        public var compressionFormat: String = ""
        /// The buffering option.
        public var bufferingHints: BufferingHints = BufferingHints()

        public init() {}

        public init(s3BackupDescription: S3DestinationDescription? = nil, bucketARN: String, encryptionConfiguration: EncryptionConfiguration, roleARN: String, processingConfiguration: ProcessingConfiguration? = nil, prefix: String? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String, bufferingHints: BufferingHints) {
            self.s3BackupDescription = s3BackupDescription
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.roleARN = roleARN
            self.processingConfiguration = processingConfiguration
            self.prefix = prefix
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct PutRecordInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The record.
        public var record: Record = Record()
        /// The name of the delivery stream.
        public var deliveryStreamName: String = ""

        public init() {}

        public init(record: Record, deliveryStreamName: String) {
            self.record = record
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct DeleteDeliveryStreamOutput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil

        public init() {}

    }

    public struct Processor: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The type of processor.
        public var type: String = ""
        /// The processor parameters.
        public var parameters: [ProcessorParameter]? = nil

        public init() {}

        public init(type: String, parameters: [ProcessorParameter]? = nil) {
            self.type = type
            self.parameters = parameters
        }

    }

    public struct ExtendedS3DestinationUpdate: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ARN of the S3 bucket.
        public var bucketARN: String? = nil
        /// The encryption configuration. If no value is specified, the default is no encryption.
        public var encryptionConfiguration: EncryptionConfiguration? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String? = nil
        /// The Amazon S3 destination for backup.
        public var s3BackupUpdate: S3DestinationUpdate? = nil
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The "YYYY/MM/DD/HH" time format prefix is automatically used for delivered S3 files. You can specify an extra prefix to be added in front of the time format prefix. Note that if the prefix ends with a slash, it appears as a folder in the S3 bucket. For more information, see Amazon S3 Object Name Format in the Amazon Kinesis Firehose Developer Guide.
        public var prefix: String? = nil
        /// Enables or disables Amazon S3 backup mode.
        public var s3BackupMode: String? = nil
        /// The CloudWatch logging options for your delivery stream.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The compression format. If no value is specified, the default is UNCOMPRESSED. 
        public var compressionFormat: String? = nil
        /// The buffering option.
        public var bufferingHints: BufferingHints? = nil

        public init() {}

        public init(bucketARN: String? = nil, encryptionConfiguration: EncryptionConfiguration? = nil, roleARN: String? = nil, s3BackupUpdate: S3DestinationUpdate? = nil, processingConfiguration: ProcessingConfiguration? = nil, prefix: String? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, compressionFormat: String? = nil, bufferingHints: BufferingHints? = nil) {
            self.bucketARN = bucketARN
            self.encryptionConfiguration = encryptionConfiguration
            self.roleARN = roleARN
            self.s3BackupUpdate = s3BackupUpdate
            self.processingConfiguration = processingConfiguration
            self.prefix = prefix
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.compressionFormat = compressionFormat
            self.bufferingHints = bufferingHints
        }

    }

    public struct CloudWatchLoggingOptions: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The CloudWatch log stream name for logging. This value is required if CloudWatch logging is enabled.
        public var logStreamName: String? = nil
        /// The CloudWatch group name for logging. This value is required if CloudWatch logging is enabled.
        public var logGroupName: String? = nil
        /// Enables or disables CloudWatch logging.
        public var enabled: Bool? = nil

        public init() {}

        public init(logStreamName: String? = nil, logGroupName: String? = nil, enabled: Bool? = nil) {
            self.logStreamName = logStreamName
            self.logGroupName = logGroupName
            self.enabled = enabled
        }

    }

    public struct DescribeDeliveryStreamInput: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ID of the destination to start returning the destination information. Currently Firehose supports one destination per delivery stream.
        public var exclusiveStartDestinationId: String? = nil
        /// The limit on the number of destinations to return. Currently, you can have one destination per delivery stream.
        public var limit: Int32? = nil
        /// The name of the delivery stream.
        public var deliveryStreamName: String = ""

        public init() {}

        public init(exclusiveStartDestinationId: String? = nil, limit: Int32? = nil, deliveryStreamName: String) {
            self.exclusiveStartDestinationId = exclusiveStartDestinationId
            self.limit = limit
            self.deliveryStreamName = deliveryStreamName
        }

    }

    public struct EncryptionConfiguration: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The encryption key.
        public var kMSEncryptionConfig: KMSEncryptionConfig? = nil
        /// Specifically override existing encryption information to ensure no encryption is used.
        public var noEncryptionConfig: String? = nil

        public init() {}

        public init(kMSEncryptionConfig: KMSEncryptionConfig? = nil, noEncryptionConfig: String? = nil) {
            self.kMSEncryptionConfig = kMSEncryptionConfig
            self.noEncryptionConfig = noEncryptionConfig
        }

    }

    public struct DeliveryStreamDescription: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The destinations.
        public var destinations: [DestinationDescription] = []
        /// The status of the delivery stream.
        public var deliveryStreamStatus: String = ""
        /// The date and time that the delivery stream was last updated.
        public var lastUpdateTimestamp: Date? = nil
        /// The name of the delivery stream.
        public var deliveryStreamName: String = ""
        /// Each time the destination is updated for a delivery stream, the version ID is changed, and the current version ID is required when updating the destination. This is so that the service knows it is applying the changes to the correct version of the delivery stream.
        public var versionId: String = ""
        /// The date and time that the delivery stream was created.
        public var createTimestamp: Date? = nil
        /// The Amazon Resource Name (ARN) of the delivery stream.
        public var deliveryStreamARN: String = ""
        /// Indicates whether there are more destinations available to list.
        public var hasMoreDestinations: Bool = false

        public init() {}

        public init(destinations: [DestinationDescription], deliveryStreamStatus: String, lastUpdateTimestamp: Date? = nil, deliveryStreamName: String, versionId: String, createTimestamp: Date? = nil, deliveryStreamARN: String, hasMoreDestinations: Bool) {
            self.destinations = destinations
            self.deliveryStreamStatus = deliveryStreamStatus
            self.lastUpdateTimestamp = lastUpdateTimestamp
            self.deliveryStreamName = deliveryStreamName
            self.versionId = versionId
            self.createTimestamp = createTimestamp
            self.deliveryStreamARN = deliveryStreamARN
            self.hasMoreDestinations = hasMoreDestinations
        }

    }

    public struct ElasticsearchDestinationDescription: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The Elasticsearch type name.
        public var typeName: String? = nil
        /// The Elasticsearch index name.
        public var indexName: String? = nil
        /// The Elasticsearch index rotation period
        public var indexRotationPeriod: String? = nil
        /// The ARN of the Amazon ES domain.
        public var domainARN: String? = nil
        /// The ARN of the AWS credentials.
        public var roleARN: String? = nil
        /// The Amazon S3 destination.
        public var s3DestinationDescription: S3DestinationDescription? = nil
        /// The data processing configuration.
        public var processingConfiguration: ProcessingConfiguration? = nil
        /// The Amazon S3 backup mode.
        public var s3BackupMode: String? = nil
        /// The CloudWatch logging options.
        public var cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil
        /// The Amazon ES retry options.
        public var retryOptions: ElasticsearchRetryOptions? = nil
        /// The buffering options.
        public var bufferingHints: ElasticsearchBufferingHints? = nil

        public init() {}

        public init(typeName: String? = nil, indexName: String? = nil, indexRotationPeriod: String? = nil, domainARN: String? = nil, roleARN: String? = nil, s3DestinationDescription: S3DestinationDescription? = nil, processingConfiguration: ProcessingConfiguration? = nil, s3BackupMode: String? = nil, cloudWatchLoggingOptions: CloudWatchLoggingOptions? = nil, retryOptions: ElasticsearchRetryOptions? = nil, bufferingHints: ElasticsearchBufferingHints? = nil) {
            self.typeName = typeName
            self.indexName = indexName
            self.indexRotationPeriod = indexRotationPeriod
            self.domainARN = domainARN
            self.roleARN = roleARN
            self.s3DestinationDescription = s3DestinationDescription
            self.processingConfiguration = processingConfiguration
            self.s3BackupMode = s3BackupMode
            self.cloudWatchLoggingOptions = cloudWatchLoggingOptions
            self.retryOptions = retryOptions
            self.bufferingHints = bufferingHints
        }

    }

    public struct ElasticsearchBufferingHints: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// Buffer incoming data to the specified size, in MBs, before delivering it to the destination. The default value is 5. We recommend setting this parameter to a value greater than the amount of data you typically ingest into the delivery stream in 10 seconds. For example, if you typically ingest data at 1 MB/sec, the value should be 10 MB or higher.
        public var sizeInMBs: Int32? = nil
        /// Buffer incoming data for the specified period of time, in seconds, before delivering it to the destination. The default value is 300 (5 minutes).
        public var intervalInSeconds: Int32? = nil

        public init() {}

        public init(sizeInMBs: Int32? = nil, intervalInSeconds: Int32? = nil) {
            self.sizeInMBs = sizeInMBs
            self.intervalInSeconds = intervalInSeconds
        }

    }

    public struct PutRecordBatchResponseEntry: AWSShape {
        /// The key for the payload
        public let _payload: String? = nil
        /// The ID of the record.
        public var recordId: String? = nil
        /// The error code for an individual record result.
        public var errorCode: String? = nil
        /// The error message for an individual record result.
        public var errorMessage: String? = nil

        public init() {}

        public init(recordId: String? = nil, errorCode: String? = nil, errorMessage: String? = nil) {
            self.recordId = recordId
            self.errorCode = errorCode
            self.errorMessage = errorMessage
        }

    }

}