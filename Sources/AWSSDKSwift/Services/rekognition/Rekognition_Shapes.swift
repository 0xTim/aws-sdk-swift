// THIS FILE IS AUTOMATICALLY GENERATED by https://github.com/noppoMan/aws-sdk-swift/blob/master/Sources/CodeGenerator/main.swift. DO NOT EDIT.
/**
The MIT License (MIT)

Copyright (c) 2017 Yuki Takei(noppoMan)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

*/

import Foundation
import AWSSDKSwiftCore

extension Rekognition {

    public struct DeleteCollectionResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "StatusCode", required: false, type: .integer)
        ]
        /// HTTP status code that indicates the result of the operation.
        public let statusCode: Int32?

        public init(statusCode: Int32? = nil) {
            self.statusCode = statusCode
        }

        private enum CodingKeys: String, CodingKey {
            case statusCode = "StatusCode"
        }
    }

    public struct ListCollectionsResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "CollectionIds", required: false, type: .list), 
            AWSShapeMember(label: "NextToken", required: false, type: .string)
        ]
        /// An array of collection IDs.
        public let collectionIds: [String]?
        /// If the result is truncated, the response provides a NextToken that you can use in the subsequent request to fetch the next set of collection IDs.
        public let nextToken: String?

        public init(collectionIds: [String]? = nil, nextToken: String? = nil) {
            self.collectionIds = collectionIds
            self.nextToken = nextToken
        }

        private enum CodingKeys: String, CodingKey {
            case collectionIds = "CollectionIds"
            case nextToken = "NextToken"
        }
    }

    public enum EmotionName: String, CustomStringConvertible, Codable {
        case happy = "HAPPY"
        case sad = "SAD"
        case angry = "ANGRY"
        case confused = "CONFUSED"
        case disgusted = "DISGUSTED"
        case surprised = "SURPRISED"
        case calm = "CALM"
        case unknown = "UNKNOWN"
        public var description: String { return self.rawValue }
    }

    public struct BoundingBox: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Height", required: false, type: .float), 
            AWSShapeMember(label: "Top", required: false, type: .float), 
            AWSShapeMember(label: "Left", required: false, type: .float), 
            AWSShapeMember(label: "Width", required: false, type: .float)
        ]
        /// Height of the bounding box as a ratio of the overall image height.
        public let height: Float?
        /// Top coordinate of the bounding box as a ratio of overall image height.
        public let top: Float?
        /// Left coordinate of the bounding box as a ratio of overall image width.
        public let left: Float?
        /// Width of the bounding box as a ratio of the overall image width.
        public let width: Float?

        public init(height: Float? = nil, top: Float? = nil, left: Float? = nil, width: Float? = nil) {
            self.height = height
            self.top = top
            self.left = left
            self.width = width
        }

        private enum CodingKeys: String, CodingKey {
            case height = "Height"
            case top = "Top"
            case left = "Left"
            case width = "Width"
        }
    }

    public struct Pose: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Yaw", required: false, type: .float), 
            AWSShapeMember(label: "Roll", required: false, type: .float), 
            AWSShapeMember(label: "Pitch", required: false, type: .float)
        ]
        /// Value representing the face rotation on the yaw axis.
        public let yaw: Float?
        /// Value representing the face rotation on the roll axis.
        public let roll: Float?
        /// Value representing the face rotation on the pitch axis.
        public let pitch: Float?

        public init(yaw: Float? = nil, roll: Float? = nil, pitch: Float? = nil) {
            self.yaw = yaw
            self.roll = roll
            self.pitch = pitch
        }

        private enum CodingKeys: String, CodingKey {
            case yaw = "Yaw"
            case roll = "Roll"
            case pitch = "Pitch"
        }
    }

    public struct DetectModerationLabelsResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "ModerationLabels", required: false, type: .list)
        ]
        /// An array of labels for explicit or suggestive adult content found in the image. The list includes the top-level label and each child label detected in the image. This is useful for filtering specific categories of content. 
        public let moderationLabels: [ModerationLabel]?

        public init(moderationLabels: [ModerationLabel]? = nil) {
            self.moderationLabels = moderationLabels
        }

        private enum CodingKeys: String, CodingKey {
            case moderationLabels = "ModerationLabels"
        }
    }

    public struct Gender: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .enum)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Gender of the face.
        public let value: GenderType?

        public init(confidence: Float? = nil, value: GenderType? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct Smile: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the face is smiling or not.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct S3Object: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Bucket", required: false, type: .string), 
            AWSShapeMember(label: "Name", required: false, type: .string), 
            AWSShapeMember(label: "Version", required: false, type: .string)
        ]
        /// Name of the S3 bucket.
        public let bucket: String?
        /// S3 object key name.
        public let name: String?
        /// If the bucket is versioning enabled, you can specify the object version. 
        public let version: String?

        public init(bucket: String? = nil, name: String? = nil, version: String? = nil) {
            self.bucket = bucket
            self.name = name
            self.version = version
        }

        private enum CodingKeys: String, CodingKey {
            case bucket = "Bucket"
            case name = "Name"
            case version = "Version"
        }
    }

    public struct DetectFacesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "OrientationCorrection", required: false, type: .enum), 
            AWSShapeMember(label: "FaceDetails", required: false, type: .list)
        ]
        ///  The orientation of the input image (counter-clockwise direction). If your application displays the image, you can use this value to correct image orientation. The bounding box coordinates returned in FaceDetails represent face locations before the image orientation is corrected.   If the input image is in .jpeg format, it might contain exchangeable image (Exif) metadata that includes the image's orientation. If so, and the Exif metadata for the input image populates the orientation field, the value of OrientationCorrection is null and the FaceDetails bounding box coordinates represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don't contain Exif metadata. 
        public let orientationCorrection: OrientationCorrection?
        /// Details of each face found in the image. 
        public let faceDetails: [FaceDetail]?

        public init(orientationCorrection: OrientationCorrection? = nil, faceDetails: [FaceDetail]? = nil) {
            self.orientationCorrection = orientationCorrection
            self.faceDetails = faceDetails
        }

        private enum CodingKeys: String, CodingKey {
            case orientationCorrection = "OrientationCorrection"
            case faceDetails = "FaceDetails"
        }
    }

    public struct IndexFacesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "OrientationCorrection", required: false, type: .enum), 
            AWSShapeMember(label: "FaceRecords", required: false, type: .list)
        ]
        /// The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct image orientation. The bounding box coordinates returned in FaceRecords represent face locations before the image orientation is corrected.   If the input image is in jpeg format, it might contain exchangeable image (Exif) metadata. If so, and the Exif metadata populates the orientation field, the value of OrientationCorrection is null and the bounding box coordinates in FaceRecords represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don't contain Exif metadata. 
        public let orientationCorrection: OrientationCorrection?
        /// An array of faces detected and added to the collection. For more information, see howitworks-index-faces. 
        public let faceRecords: [FaceRecord]?

        public init(orientationCorrection: OrientationCorrection? = nil, faceRecords: [FaceRecord]? = nil) {
            self.orientationCorrection = orientationCorrection
            self.faceRecords = faceRecords
        }

        private enum CodingKeys: String, CodingKey {
            case orientationCorrection = "OrientationCorrection"
            case faceRecords = "FaceRecords"
        }
    }

    public struct FaceDetail: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Sunglasses", required: false, type: .structure), 
            AWSShapeMember(label: "Gender", required: false, type: .structure), 
            AWSShapeMember(label: "EyesOpen", required: false, type: .structure), 
            AWSShapeMember(label: "Smile", required: false, type: .structure), 
            AWSShapeMember(label: "MouthOpen", required: false, type: .structure), 
            AWSShapeMember(label: "BoundingBox", required: false, type: .structure), 
            AWSShapeMember(label: "Pose", required: false, type: .structure), 
            AWSShapeMember(label: "AgeRange", required: false, type: .structure), 
            AWSShapeMember(label: "Eyeglasses", required: false, type: .structure), 
            AWSShapeMember(label: "Landmarks", required: false, type: .list), 
            AWSShapeMember(label: "Beard", required: false, type: .structure), 
            AWSShapeMember(label: "Quality", required: false, type: .structure), 
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Mustache", required: false, type: .structure), 
            AWSShapeMember(label: "Emotions", required: false, type: .list)
        ]
        /// Indicates whether or not the face is wearing sunglasses, and the confidence level in the determination.
        public let sunglasses: Sunglasses?
        /// Gender of the face and the confidence level in the determination.
        public let gender: Gender?
        /// Indicates whether or not the eyes on the face are open, and the confidence level in the determination.
        public let eyesOpen: EyeOpen?
        /// Indicates whether or not the face is smiling, and the confidence level in the determination.
        public let smile: Smile?
        /// Indicates whether or not the mouth on the face is open, and the confidence level in the determination.
        public let mouthOpen: MouthOpen?
        /// Bounding box of the face.
        public let boundingBox: BoundingBox?
        /// Indicates the pose of the face as determined by its pitch, roll, and yaw.
        public let pose: Pose?
        /// The estimated age range, in years, for the face. Low represents the lowest estimated age and High represents the highest estimated age.
        public let ageRange: AgeRange?
        /// Indicates whether or not the face is wearing eye glasses, and the confidence level in the determination.
        public let eyeglasses: Eyeglasses?
        /// Indicates the location of landmarks on the face.
        public let landmarks: [Landmark]?
        /// Indicates whether or not the face has a beard, and the confidence level in the determination.
        public let beard: Beard?
        /// Identifies image brightness and sharpness.
        public let quality: ImageQuality?
        /// Confidence level that the bounding box contains a face (and not a different object such as a tree).
        public let confidence: Float?
        /// Indicates whether or not the face has a mustache, and the confidence level in the determination.
        public let mustache: Mustache?
        /// The emotions detected on the face, and the confidence level in the determination. For example, HAPPY, SAD, and ANGRY. 
        public let emotions: [Emotion]?

        public init(sunglasses: Sunglasses? = nil, gender: Gender? = nil, eyesOpen: EyeOpen? = nil, smile: Smile? = nil, mouthOpen: MouthOpen? = nil, boundingBox: BoundingBox? = nil, pose: Pose? = nil, ageRange: AgeRange? = nil, eyeglasses: Eyeglasses? = nil, landmarks: [Landmark]? = nil, beard: Beard? = nil, quality: ImageQuality? = nil, confidence: Float? = nil, mustache: Mustache? = nil, emotions: [Emotion]? = nil) {
            self.sunglasses = sunglasses
            self.gender = gender
            self.eyesOpen = eyesOpen
            self.smile = smile
            self.mouthOpen = mouthOpen
            self.boundingBox = boundingBox
            self.pose = pose
            self.ageRange = ageRange
            self.eyeglasses = eyeglasses
            self.landmarks = landmarks
            self.beard = beard
            self.quality = quality
            self.confidence = confidence
            self.mustache = mustache
            self.emotions = emotions
        }

        private enum CodingKeys: String, CodingKey {
            case sunglasses = "Sunglasses"
            case gender = "Gender"
            case eyesOpen = "EyesOpen"
            case smile = "Smile"
            case mouthOpen = "MouthOpen"
            case boundingBox = "BoundingBox"
            case pose = "Pose"
            case ageRange = "AgeRange"
            case eyeglasses = "Eyeglasses"
            case landmarks = "Landmarks"
            case beard = "Beard"
            case quality = "Quality"
            case confidence = "Confidence"
            case mustache = "Mustache"
            case emotions = "Emotions"
        }
    }

    public struct CompareFacesMatch: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Face", required: false, type: .structure), 
            AWSShapeMember(label: "Similarity", required: false, type: .float)
        ]
        /// Provides face metadata (bounding box and confidence that the bounding box actually contains a face).
        public let face: ComparedFace?
        /// Level of confidence that the faces match.
        public let similarity: Float?

        public init(face: ComparedFace? = nil, similarity: Float? = nil) {
            self.face = face
            self.similarity = similarity
        }

        private enum CodingKeys: String, CodingKey {
            case face = "Face"
            case similarity = "Similarity"
        }
    }

    public struct Celebrity: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Face", required: false, type: .structure), 
            AWSShapeMember(label: "Urls", required: false, type: .list), 
            AWSShapeMember(label: "MatchConfidence", required: false, type: .float), 
            AWSShapeMember(label: "Name", required: false, type: .string), 
            AWSShapeMember(label: "Id", required: false, type: .string)
        ]
        /// Provides information about the celebrity's face, such as its location on the image.
        public let face: ComparedFace?
        /// An array of URLs pointing to additional information about the celebrity. If there is no additional information about the celebrity, this list is empty.
        public let urls: [String]?
        /// The confidence, in percentage, that Rekognition has that the recognized face is the celebrity.
        public let matchConfidence: Float?
        /// The name of the celebrity.
        public let name: String?
        /// A unique identifier for the celebrity. 
        public let id: String?

        public init(face: ComparedFace? = nil, urls: [String]? = nil, matchConfidence: Float? = nil, name: String? = nil, id: String? = nil) {
            self.face = face
            self.urls = urls
            self.matchConfidence = matchConfidence
            self.name = name
            self.id = id
        }

        private enum CodingKeys: String, CodingKey {
            case face = "Face"
            case urls = "Urls"
            case matchConfidence = "MatchConfidence"
            case name = "Name"
            case id = "Id"
        }
    }

    public struct SearchFacesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "FaceMatches", required: false, type: .list), 
            AWSShapeMember(label: "SearchedFaceId", required: false, type: .string)
        ]
        /// An array of faces that matched the input face, along with the confidence in the match.
        public let faceMatches: [FaceMatch]?
        /// ID of the face that was searched for matches in a collection.
        public let searchedFaceId: String?

        public init(faceMatches: [FaceMatch]? = nil, searchedFaceId: String? = nil) {
            self.faceMatches = faceMatches
            self.searchedFaceId = searchedFaceId
        }

        private enum CodingKeys: String, CodingKey {
            case faceMatches = "FaceMatches"
            case searchedFaceId = "SearchedFaceId"
        }
    }

    public struct SearchFacesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "FaceMatchThreshold", required: false, type: .float), 
            AWSShapeMember(label: "MaxFaces", required: false, type: .integer), 
            AWSShapeMember(label: "CollectionId", required: true, type: .string), 
            AWSShapeMember(label: "FaceId", required: true, type: .string)
        ]
        /// Optional value specifying the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%.
        public let faceMatchThreshold: Float?
        /// Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.
        public let maxFaces: Int32?
        /// ID of the collection the face belongs to.
        public let collectionId: String
        /// ID of a face to find matches for in the collection.
        public let faceId: String

        public init(faceMatchThreshold: Float? = nil, maxFaces: Int32? = nil, collectionId: String, faceId: String) {
            self.faceMatchThreshold = faceMatchThreshold
            self.maxFaces = maxFaces
            self.collectionId = collectionId
            self.faceId = faceId
        }

        private enum CodingKeys: String, CodingKey {
            case faceMatchThreshold = "FaceMatchThreshold"
            case maxFaces = "MaxFaces"
            case collectionId = "CollectionId"
            case faceId = "FaceId"
        }
    }

    public struct Mustache: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the face has mustache or not.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct ModerationLabel: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Name", required: false, type: .string), 
            AWSShapeMember(label: "ParentName", required: false, type: .string)
        ]
        /// Specifies the confidence that Amazon Rekognition has that the label has been correctly identified. If you don't specify the MinConfidence parameter in the call to DetectModerationLabels, the operation returns labels with a confidence value greater than or equal to 50 percent.
        public let confidence: Float?
        /// The label name for the type of content detected in the image.
        public let name: String?
        /// The name for the parent label. Labels at the top-level of the hierarchy have the parent label "".
        public let parentName: String?

        public init(confidence: Float? = nil, name: String? = nil, parentName: String? = nil) {
            self.confidence = confidence
            self.name = name
            self.parentName = parentName
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case name = "Name"
            case parentName = "ParentName"
        }
    }

    public struct EyeOpen: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the eyes on the face are open.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public enum Attribute: String, CustomStringConvertible, Codable {
        case `default` = "DEFAULT"
        case all = "ALL"
        public var description: String { return self.rawValue }
    }

    public struct DetectFacesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Image", required: true, type: .structure), 
            AWSShapeMember(label: "Attributes", required: false, type: .list)
        ]
        /// The image in which you want to detect faces. You can specify a blob or an S3 object. 
        public let image: Image
        /// An array of facial attributes you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for Attributes or if you specify ["DEFAULT"], the API returns the following subset of facial attributes: BoundingBox, Confidence, Pose, Quality and Landmarks. If you provide ["ALL"], all facial attributes are returned but the operation will take longer to complete. If you provide both, ["ALL", "DEFAULT"], the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). 
        public let attributes: [Attribute]?

        public init(image: Image, attributes: [Attribute]? = nil) {
            self.image = image
            self.attributes = attributes
        }

        private enum CodingKeys: String, CodingKey {
            case image = "Image"
            case attributes = "Attributes"
        }
    }

    public struct Beard: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the face has beard or not.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct Sunglasses: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the face is wearing sunglasses or not.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct Image: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Bytes", required: false, type: .blob), 
            AWSShapeMember(label: "S3Object", required: false, type: .structure)
        ]
        /// Blob of image bytes up to 5 MBs.
        public let bytes: Data?
        /// Identifies an S3 object as the image source.
        public let s3Object: S3Object?

        public init(bytes: Data? = nil, s3Object: S3Object? = nil) {
            self.bytes = bytes
            self.s3Object = s3Object
        }

        private enum CodingKeys: String, CodingKey {
            case bytes = "Bytes"
            case s3Object = "S3Object"
        }
    }

    public struct AgeRange: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "High", required: false, type: .integer), 
            AWSShapeMember(label: "Low", required: false, type: .integer)
        ]
        /// The highest estimated age.
        public let high: Int32?
        /// The lowest estimated age.
        public let low: Int32?

        public init(high: Int32? = nil, low: Int32? = nil) {
            self.high = high
            self.low = low
        }

        private enum CodingKeys: String, CodingKey {
            case high = "High"
            case low = "Low"
        }
    }

    public struct Eyeglasses: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the face is wearing eye glasses or not.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct DeleteCollectionRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "CollectionId", required: true, type: .string)
        ]
        /// ID of the collection to delete.
        public let collectionId: String

        public init(collectionId: String) {
            self.collectionId = collectionId
        }

        private enum CodingKeys: String, CodingKey {
            case collectionId = "CollectionId"
        }
    }

    public struct CreateCollectionRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "CollectionId", required: true, type: .string)
        ]
        /// ID for the collection that you are creating.
        public let collectionId: String

        public init(collectionId: String) {
            self.collectionId = collectionId
        }

        private enum CodingKeys: String, CodingKey {
            case collectionId = "CollectionId"
        }
    }

    public struct DetectLabelsResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "OrientationCorrection", required: false, type: .enum), 
            AWSShapeMember(label: "Labels", required: false, type: .list)
        ]
        ///  The orientation of the input image (counter-clockwise direction). If your application displays the image, you can use this value to correct the orientation. If Amazon Rekognition detects that the input image was rotated (for example, by 90 degrees), it first corrects the orientation before detecting the labels.   If the input image Exif metadata populates the orientation field, Amazon Rekognition does not perform orientation correction and the value of OrientationCorrection will be null. 
        public let orientationCorrection: OrientationCorrection?
        /// An array of labels for the real-world objects detected. 
        public let labels: [Label]?

        public init(orientationCorrection: OrientationCorrection? = nil, labels: [Label]? = nil) {
            self.orientationCorrection = orientationCorrection
            self.labels = labels
        }

        private enum CodingKeys: String, CodingKey {
            case orientationCorrection = "OrientationCorrection"
            case labels = "Labels"
        }
    }

    public struct ListFacesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "NextToken", required: false, type: .string), 
            AWSShapeMember(label: "CollectionId", required: true, type: .string), 
            AWSShapeMember(label: "MaxResults", required: false, type: .integer)
        ]
        /// If the previous response was incomplete (because there is more data to retrieve), Amazon Rekognition returns a pagination token in the response. You can use this pagination token to retrieve the next set of faces.
        public let nextToken: String?
        /// ID of the collection from which to list the faces.
        public let collectionId: String
        /// Maximum number of faces to return.
        public let maxResults: Int32?

        public init(nextToken: String? = nil, collectionId: String, maxResults: Int32? = nil) {
            self.nextToken = nextToken
            self.collectionId = collectionId
            self.maxResults = maxResults
        }

        private enum CodingKeys: String, CodingKey {
            case nextToken = "NextToken"
            case collectionId = "CollectionId"
            case maxResults = "MaxResults"
        }
    }

    public struct ComparedSourceImageFace: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "BoundingBox", required: false, type: .structure)
        ]
        /// Confidence level that the selected bounding box contains a face.
        public let confidence: Float?
        /// Bounding box of the face.
        public let boundingBox: BoundingBox?

        public init(confidence: Float? = nil, boundingBox: BoundingBox? = nil) {
            self.confidence = confidence
            self.boundingBox = boundingBox
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case boundingBox = "BoundingBox"
        }
    }

    public struct ListFacesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Faces", required: false, type: .list), 
            AWSShapeMember(label: "NextToken", required: false, type: .string)
        ]
        /// An array of Face objects. 
        public let faces: [Face]?
        /// If the response is truncated, Amazon Rekognition returns this token that you can use in the subsequent request to retrieve the next set of faces.
        public let nextToken: String?

        public init(faces: [Face]? = nil, nextToken: String? = nil) {
            self.faces = faces
            self.nextToken = nextToken
        }

        private enum CodingKeys: String, CodingKey {
            case faces = "Faces"
            case nextToken = "NextToken"
        }
    }

    public struct Landmark: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "X", required: false, type: .float), 
            AWSShapeMember(label: "Type", required: false, type: .enum), 
            AWSShapeMember(label: "Y", required: false, type: .float)
        ]
        /// x-coordinate from the top left of the landmark expressed as the ration of the width of the image. For example, if the images is 700x200 and the x-coordinate of the landmark is at 350 pixels, this value is 0.5. 
        public let x: Float?
        /// Type of the landmark.
        public let `type`: LandmarkType?
        /// y-coordinate from the top left of the landmark expressed as the ration of the height of the image. For example, if the images is 700x200 and the y-coordinate of the landmark is at 100 pixels, this value is 0.5.
        public let y: Float?

        public init(x: Float? = nil, type: LandmarkType? = nil, y: Float? = nil) {
            self.x = x
            self.`type` = `type`
            self.y = y
        }

        private enum CodingKeys: String, CodingKey {
            case x = "X"
            case `type` = "Type"
            case y = "Y"
        }
    }

    public struct SearchFacesByImageResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "SearchedFaceConfidence", required: false, type: .float), 
            AWSShapeMember(label: "FaceMatches", required: false, type: .list), 
            AWSShapeMember(label: "SearchedFaceBoundingBox", required: false, type: .structure)
        ]
        /// The level of confidence that the searchedFaceBoundingBox, contains a face.
        public let searchedFaceConfidence: Float?
        /// An array of faces that match the input face, along with the confidence in the match.
        public let faceMatches: [FaceMatch]?
        /// The bounding box around the face in the input image that Amazon Rekognition used for the search.
        public let searchedFaceBoundingBox: BoundingBox?

        public init(searchedFaceConfidence: Float? = nil, faceMatches: [FaceMatch]? = nil, searchedFaceBoundingBox: BoundingBox? = nil) {
            self.searchedFaceConfidence = searchedFaceConfidence
            self.faceMatches = faceMatches
            self.searchedFaceBoundingBox = searchedFaceBoundingBox
        }

        private enum CodingKeys: String, CodingKey {
            case searchedFaceConfidence = "SearchedFaceConfidence"
            case faceMatches = "FaceMatches"
            case searchedFaceBoundingBox = "SearchedFaceBoundingBox"
        }
    }

    public enum OrientationCorrection: String, CustomStringConvertible, Codable {
        case rotate0 = "ROTATE_0"
        case rotate90 = "ROTATE_90"
        case rotate180 = "ROTATE_180"
        case rotate270 = "ROTATE_270"
        public var description: String { return self.rawValue }
    }

    public struct Emotion: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Type", required: false, type: .enum)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Type of emotion detected.
        public let `type`: EmotionName?

        public init(confidence: Float? = nil, type: EmotionName? = nil) {
            self.confidence = confidence
            self.`type` = `type`
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case `type` = "Type"
        }
    }

    public struct DeleteFacesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "FaceIds", required: true, type: .list), 
            AWSShapeMember(label: "CollectionId", required: true, type: .string)
        ]
        /// An array of face IDs to delete.
        public let faceIds: [String]
        /// Collection from which to remove the specific faces.
        public let collectionId: String

        public init(faceIds: [String], collectionId: String) {
            self.faceIds = faceIds
            self.collectionId = collectionId
        }

        private enum CodingKeys: String, CodingKey {
            case faceIds = "FaceIds"
            case collectionId = "CollectionId"
        }
    }

    public struct DeleteFacesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "DeletedFaces", required: false, type: .list)
        ]
        /// An array of strings (face IDs) of the faces that were deleted.
        public let deletedFaces: [String]?

        public init(deletedFaces: [String]? = nil) {
            self.deletedFaces = deletedFaces
        }

        private enum CodingKeys: String, CodingKey {
            case deletedFaces = "DeletedFaces"
        }
    }

    public struct GetCelebrityInfoRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Id", required: true, type: .string)
        ]
        /// The ID for the celebrity. You get the celebrity ID from a call to the operation, which recognizes celebrities in an image. 
        public let id: String

        public init(id: String) {
            self.id = id
        }

        private enum CodingKeys: String, CodingKey {
            case id = "Id"
        }
    }

    public struct GetCelebrityInfoResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Name", required: false, type: .string), 
            AWSShapeMember(label: "Urls", required: false, type: .list)
        ]
        /// The name of the celebrity.
        public let name: String?
        /// An array of URLs pointing to additional celebrity information. 
        public let urls: [String]?

        public init(name: String? = nil, urls: [String]? = nil) {
            self.name = name
            self.urls = urls
        }

        private enum CodingKeys: String, CodingKey {
            case name = "Name"
            case urls = "Urls"
        }
    }

    public struct ComparedFace: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "BoundingBox", required: false, type: .structure), 
            AWSShapeMember(label: "Landmarks", required: false, type: .list), 
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Pose", required: false, type: .structure), 
            AWSShapeMember(label: "Quality", required: false, type: .structure)
        ]
        /// Bounding box of the face.
        public let boundingBox: BoundingBox?
        /// An array of facial landmarks.
        public let landmarks: [Landmark]?
        /// Level of confidence that what the bounding box contains is a face.
        public let confidence: Float?
        /// Indicates the pose of the face as determined by its pitch, roll, and yaw.
        public let pose: Pose?
        /// Identifies face image brightness and sharpness. 
        public let quality: ImageQuality?

        public init(boundingBox: BoundingBox? = nil, landmarks: [Landmark]? = nil, confidence: Float? = nil, pose: Pose? = nil, quality: ImageQuality? = nil) {
            self.boundingBox = boundingBox
            self.landmarks = landmarks
            self.confidence = confidence
            self.pose = pose
            self.quality = quality
        }

        private enum CodingKeys: String, CodingKey {
            case boundingBox = "BoundingBox"
            case landmarks = "Landmarks"
            case confidence = "Confidence"
            case pose = "Pose"
            case quality = "Quality"
        }
    }

    public struct SearchFacesByImageRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Image", required: true, type: .structure), 
            AWSShapeMember(label: "FaceMatchThreshold", required: false, type: .float), 
            AWSShapeMember(label: "MaxFaces", required: false, type: .integer), 
            AWSShapeMember(label: "CollectionId", required: true, type: .string)
        ]
        /// The input image as bytes or an S3 object.
        public let image: Image
        /// (Optional) Specifies the minimum confidence in the face match to return. For example, don't return any matches where confidence in matches is less than 70%.
        public let faceMatchThreshold: Float?
        /// Maximum number of faces to return. The operation returns the maximum number of faces with the highest confidence in the match.
        public let maxFaces: Int32?
        /// ID of the collection to search.
        public let collectionId: String

        public init(image: Image, faceMatchThreshold: Float? = nil, maxFaces: Int32? = nil, collectionId: String) {
            self.image = image
            self.faceMatchThreshold = faceMatchThreshold
            self.maxFaces = maxFaces
            self.collectionId = collectionId
        }

        private enum CodingKeys: String, CodingKey {
            case image = "Image"
            case faceMatchThreshold = "FaceMatchThreshold"
            case maxFaces = "MaxFaces"
            case collectionId = "CollectionId"
        }
    }

    public struct FaceMatch: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Face", required: false, type: .structure), 
            AWSShapeMember(label: "Similarity", required: false, type: .float)
        ]
        /// Describes the face properties such as the bounding box, face ID, image ID of the source image, and external image ID that you assigned.
        public let face: Face?
        /// Confidence in the match of this face with the input face.
        public let similarity: Float?

        public init(face: Face? = nil, similarity: Float? = nil) {
            self.face = face
            self.similarity = similarity
        }

        private enum CodingKeys: String, CodingKey {
            case face = "Face"
            case similarity = "Similarity"
        }
    }

    public struct DetectModerationLabelsRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Image", required: true, type: .structure), 
            AWSShapeMember(label: "MinConfidence", required: false, type: .float)
        ]
        /// The input image as bytes or an S3 object.
        public let image: Image
        /// Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with a confidence level lower than this specified value. If you don't specify MinConfidence, the operation returns labels with confidence values greater than or equal to 50 percent.
        public let minConfidence: Float?

        public init(image: Image, minConfidence: Float? = nil) {
            self.image = image
            self.minConfidence = minConfidence
        }

        private enum CodingKeys: String, CodingKey {
            case image = "Image"
            case minConfidence = "MinConfidence"
        }
    }

    public struct Label: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Name", required: false, type: .string)
        ]
        /// Level of confidence.
        public let confidence: Float?
        /// The name (label) of the object.
        public let name: String?

        public init(confidence: Float? = nil, name: String? = nil) {
            self.confidence = confidence
            self.name = name
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case name = "Name"
        }
    }

    public struct ListCollectionsRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "NextToken", required: false, type: .string), 
            AWSShapeMember(label: "MaxResults", required: false, type: .integer)
        ]
        /// Pagination token from the previous response.
        public let nextToken: String?
        /// Maximum number of collection IDs to return.
        public let maxResults: Int32?

        public init(nextToken: String? = nil, maxResults: Int32? = nil) {
            self.nextToken = nextToken
            self.maxResults = maxResults
        }

        private enum CodingKeys: String, CodingKey {
            case nextToken = "NextToken"
            case maxResults = "MaxResults"
        }
    }

    public struct DetectLabelsRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Image", required: true, type: .structure), 
            AWSShapeMember(label: "MaxLabels", required: false, type: .integer), 
            AWSShapeMember(label: "MinConfidence", required: false, type: .float)
        ]
        /// The input image. You can provide a blob of image bytes or an S3 object.
        public let image: Image
        /// Maximum number of labels you want the service to return in the response. The service returns the specified number of highest confidence labels. 
        public let maxLabels: Int32?
        /// Specifies the minimum confidence level for the labels to return. Amazon Rekognition doesn't return any labels with confidence lower than this specified value. If MinConfidence is not specified, the operation returns labels with a confidence values greater than or equal to 50 percent.
        public let minConfidence: Float?

        public init(image: Image, maxLabels: Int32? = nil, minConfidence: Float? = nil) {
            self.image = image
            self.maxLabels = maxLabels
            self.minConfidence = minConfidence
        }

        private enum CodingKeys: String, CodingKey {
            case image = "Image"
            case maxLabels = "MaxLabels"
            case minConfidence = "MinConfidence"
        }
    }

    public struct CreateCollectionResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "CollectionArn", required: false, type: .string), 
            AWSShapeMember(label: "StatusCode", required: false, type: .integer)
        ]
        /// Amazon Resource Name (ARN) of the collection. You can use this to manage permissions on your resources. 
        public let collectionArn: String?
        /// HTTP status code indicating the result of the operation.
        public let statusCode: Int32?

        public init(collectionArn: String? = nil, statusCode: Int32? = nil) {
            self.collectionArn = collectionArn
            self.statusCode = statusCode
        }

        private enum CodingKeys: String, CodingKey {
            case collectionArn = "CollectionArn"
            case statusCode = "StatusCode"
        }
    }

    public struct FaceRecord: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Face", required: false, type: .structure), 
            AWSShapeMember(label: "FaceDetail", required: false, type: .structure)
        ]
        /// Describes the face properties such as the bounding box, face ID, image ID of the input image, and external image ID that you assigned. 
        public let face: Face?
        /// Structure containing attributes of the face that the algorithm detected.
        public let faceDetail: FaceDetail?

        public init(face: Face? = nil, faceDetail: FaceDetail? = nil) {
            self.face = face
            self.faceDetail = faceDetail
        }

        private enum CodingKeys: String, CodingKey {
            case face = "Face"
            case faceDetail = "FaceDetail"
        }
    }

    public enum GenderType: String, CustomStringConvertible, Codable {
        case male = "MALE"
        case female = "FEMALE"
        public var description: String { return self.rawValue }
    }

    public struct Face: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "BoundingBox", required: false, type: .structure), 
            AWSShapeMember(label: "ExternalImageId", required: false, type: .string), 
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "FaceId", required: false, type: .string), 
            AWSShapeMember(label: "ImageId", required: false, type: .string)
        ]
        /// Bounding box of the face.
        public let boundingBox: BoundingBox?
        /// Identifier that you assign to all the faces in the input image.
        public let externalImageId: String?
        /// Confidence level that the bounding box contains a face (and not a different object such as a tree).
        public let confidence: Float?
        /// Unique identifier that Amazon Rekognition assigns to the face.
        public let faceId: String?
        /// Unique identifier that Amazon Rekognition assigns to the input image.
        public let imageId: String?

        public init(boundingBox: BoundingBox? = nil, externalImageId: String? = nil, confidence: Float? = nil, faceId: String? = nil, imageId: String? = nil) {
            self.boundingBox = boundingBox
            self.externalImageId = externalImageId
            self.confidence = confidence
            self.faceId = faceId
            self.imageId = imageId
        }

        private enum CodingKeys: String, CodingKey {
            case boundingBox = "BoundingBox"
            case externalImageId = "ExternalImageId"
            case confidence = "Confidence"
            case faceId = "FaceId"
            case imageId = "ImageId"
        }
    }

    public struct CompareFacesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "SourceImage", required: true, type: .structure), 
            AWSShapeMember(label: "TargetImage", required: true, type: .structure), 
            AWSShapeMember(label: "SimilarityThreshold", required: false, type: .float)
        ]
        /// The source image, either as bytes or as an S3 object.
        public let sourceImage: Image
        /// The target image, either as bytes or as an S3 object.
        public let targetImage: Image
        /// The minimum level of confidence in the face matches that a match must meet to be included in the FaceMatches array.
        public let similarityThreshold: Float?

        public init(sourceImage: Image, targetImage: Image, similarityThreshold: Float? = nil) {
            self.sourceImage = sourceImage
            self.targetImage = targetImage
            self.similarityThreshold = similarityThreshold
        }

        private enum CodingKeys: String, CodingKey {
            case sourceImage = "SourceImage"
            case targetImage = "TargetImage"
            case similarityThreshold = "SimilarityThreshold"
        }
    }

    public struct RecognizeCelebritiesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Image", required: true, type: .structure)
        ]
        /// The input image to use for celebrity recognition.
        public let image: Image

        public init(image: Image) {
            self.image = image
        }

        private enum CodingKeys: String, CodingKey {
            case image = "Image"
        }
    }

    public struct RecognizeCelebritiesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "OrientationCorrection", required: false, type: .enum), 
            AWSShapeMember(label: "CelebrityFaces", required: false, type: .list), 
            AWSShapeMember(label: "UnrecognizedFaces", required: false, type: .list)
        ]
        /// The orientation of the input image (counterclockwise direction). If your application displays the image, you can use this value to correct the orientation. The bounding box coordinates returned in CelebrityFaces and UnrecognizedFaces represent face locations before the image orientation is corrected.   If the input image is in .jpeg format, it might contain exchangeable image (Exif) metadata that includes the image's orientation. If so, and the Exif metadata for the input image populates the orientation field, the value of OrientationCorrection is null and the CelebrityFaces and UnrecognizedFaces bounding box coordinates represent face locations after Exif metadata is used to correct the image orientation. Images in .png format don't contain Exif metadata.  
        public let orientationCorrection: OrientationCorrection?
        /// Details about each celebrity found in the image. Amazon Rekognition can detect a maximum of 15 celebrities in an image.
        public let celebrityFaces: [Celebrity]?
        /// Details about each unrecognized face in the image.
        public let unrecognizedFaces: [ComparedFace]?

        public init(orientationCorrection: OrientationCorrection? = nil, celebrityFaces: [Celebrity]? = nil, unrecognizedFaces: [ComparedFace]? = nil) {
            self.orientationCorrection = orientationCorrection
            self.celebrityFaces = celebrityFaces
            self.unrecognizedFaces = unrecognizedFaces
        }

        private enum CodingKeys: String, CodingKey {
            case orientationCorrection = "OrientationCorrection"
            case celebrityFaces = "CelebrityFaces"
            case unrecognizedFaces = "UnrecognizedFaces"
        }
    }

    public struct MouthOpen: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Confidence", required: false, type: .float), 
            AWSShapeMember(label: "Value", required: false, type: .boolean)
        ]
        /// Level of confidence in the determination.
        public let confidence: Float?
        /// Boolean value that indicates whether the mouth on the face is open or not.
        public let value: Bool?

        public init(confidence: Float? = nil, value: Bool? = nil) {
            self.confidence = confidence
            self.value = value
        }

        private enum CodingKeys: String, CodingKey {
            case confidence = "Confidence"
            case value = "Value"
        }
    }

    public struct CompareFacesResponse: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "TargetImageOrientationCorrection", required: false, type: .enum), 
            AWSShapeMember(label: "UnmatchedFaces", required: false, type: .list), 
            AWSShapeMember(label: "SourceImageFace", required: false, type: .structure), 
            AWSShapeMember(label: "FaceMatches", required: false, type: .list), 
            AWSShapeMember(label: "SourceImageOrientationCorrection", required: false, type: .enum)
        ]
        ///  The orientation of the target image (in counterclockwise direction). If your application displays the target image, you can use this value to correct the orientation of the image. The bounding box coordinates returned in FaceMatches and UnmatchedFaces represent face locations before the image orientation is corrected.   If the target image is in .jpg format, it might contain Exif metadata that includes the orientation of the image. If the Exif metadata for the target image populates the orientation field, the value of OrientationCorrection is null and the bounding box coordinates in FaceMatches and UnmatchedFaces represent the location of the face after Exif metadata is used to correct the orientation. Images in .png format don't contain Exif metadata. 
        public let targetImageOrientationCorrection: OrientationCorrection?
        /// An array of faces in the target image that did not match the source image face.
        public let unmatchedFaces: [ComparedFace]?
        /// The face in the source image that was used for comparison.
        public let sourceImageFace: ComparedSourceImageFace?
        /// An array of faces in the target image that match the source image face. Each CompareFacesMatch object provides the bounding box, the confidence level that the bounding box contains a face, and the similarity score for the face in the bounding box and the face in the source image.
        public let faceMatches: [CompareFacesMatch]?
        ///  The orientation of the source image (counterclockwise direction). If your application displays the source image, you can use this value to correct image orientation. The bounding box coordinates returned in SourceImageFace represent the location of the face before the image orientation is corrected.   If the source image is in .jpeg format, it might contain exchangeable image (Exif) metadata that includes the image's orientation. If the Exif metadata for the source image populates the orientation field, the value of OrientationCorrection is null and the SourceImageFace bounding box coordinates represent the location of the face after Exif metadata is used to correct the orientation. Images in .png format don't contain Exif metadata. 
        public let sourceImageOrientationCorrection: OrientationCorrection?

        public init(targetImageOrientationCorrection: OrientationCorrection? = nil, unmatchedFaces: [ComparedFace]? = nil, sourceImageFace: ComparedSourceImageFace? = nil, faceMatches: [CompareFacesMatch]? = nil, sourceImageOrientationCorrection: OrientationCorrection? = nil) {
            self.targetImageOrientationCorrection = targetImageOrientationCorrection
            self.unmatchedFaces = unmatchedFaces
            self.sourceImageFace = sourceImageFace
            self.faceMatches = faceMatches
            self.sourceImageOrientationCorrection = sourceImageOrientationCorrection
        }

        private enum CodingKeys: String, CodingKey {
            case targetImageOrientationCorrection = "TargetImageOrientationCorrection"
            case unmatchedFaces = "UnmatchedFaces"
            case sourceImageFace = "SourceImageFace"
            case faceMatches = "FaceMatches"
            case sourceImageOrientationCorrection = "SourceImageOrientationCorrection"
        }
    }

    public enum LandmarkType: String, CustomStringConvertible, Codable {
        case eyeLeft = "EYE_LEFT"
        case eyeRight = "EYE_RIGHT"
        case nose = "NOSE"
        case mouthLeft = "MOUTH_LEFT"
        case mouthRight = "MOUTH_RIGHT"
        case leftEyebrowLeft = "LEFT_EYEBROW_LEFT"
        case leftEyebrowRight = "LEFT_EYEBROW_RIGHT"
        case leftEyebrowUp = "LEFT_EYEBROW_UP"
        case rightEyebrowLeft = "RIGHT_EYEBROW_LEFT"
        case rightEyebrowRight = "RIGHT_EYEBROW_RIGHT"
        case rightEyebrowUp = "RIGHT_EYEBROW_UP"
        case leftEyeLeft = "LEFT_EYE_LEFT"
        case leftEyeRight = "LEFT_EYE_RIGHT"
        case leftEyeUp = "LEFT_EYE_UP"
        case leftEyeDown = "LEFT_EYE_DOWN"
        case rightEyeLeft = "RIGHT_EYE_LEFT"
        case rightEyeRight = "RIGHT_EYE_RIGHT"
        case rightEyeUp = "RIGHT_EYE_UP"
        case rightEyeDown = "RIGHT_EYE_DOWN"
        case noseLeft = "NOSE_LEFT"
        case noseRight = "NOSE_RIGHT"
        case mouthUp = "MOUTH_UP"
        case mouthDown = "MOUTH_DOWN"
        case leftPupil = "LEFT_PUPIL"
        case rightPupil = "RIGHT_PUPIL"
        public var description: String { return self.rawValue }
    }

    public struct ImageQuality: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Sharpness", required: false, type: .float), 
            AWSShapeMember(label: "Brightness", required: false, type: .float)
        ]
        /// Value representing sharpness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a sharper face image.
        public let sharpness: Float?
        /// Value representing brightness of the face. The service returns a value between 0 and 100 (inclusive). A higher value indicates a brighter face image.
        public let brightness: Float?

        public init(sharpness: Float? = nil, brightness: Float? = nil) {
            self.sharpness = sharpness
            self.brightness = brightness
        }

        private enum CodingKeys: String, CodingKey {
            case sharpness = "Sharpness"
            case brightness = "Brightness"
        }
    }

    public struct IndexFacesRequest: AWSShape {
        /// The key for the payload
        public static var members: [AWSShapeMember] = [
            AWSShapeMember(label: "Image", required: true, type: .structure), 
            AWSShapeMember(label: "ExternalImageId", required: false, type: .string), 
            AWSShapeMember(label: "CollectionId", required: true, type: .string), 
            AWSShapeMember(label: "DetectionAttributes", required: false, type: .list)
        ]
        /// The input image as bytes or an S3 object.
        public let image: Image
        /// ID you want to assign to all the faces detected in the image.
        public let externalImageId: String?
        /// The ID of an existing collection to which you want to add the faces that are detected in the input images.
        public let collectionId: String
        /// An array of facial attributes that you want to be returned. This can be the default list of attributes or all attributes. If you don't specify a value for Attributes or if you specify ["DEFAULT"], the API returns the following subset of facial attributes: BoundingBox, Confidence, Pose, Quality and Landmarks. If you provide ["ALL"], all facial attributes are returned but the operation will take longer to complete. If you provide both, ["ALL", "DEFAULT"], the service uses a logical AND operator to determine which attributes to return (in this case, all attributes). 
        public let detectionAttributes: [Attribute]?

        public init(image: Image, externalImageId: String? = nil, collectionId: String, detectionAttributes: [Attribute]? = nil) {
            self.image = image
            self.externalImageId = externalImageId
            self.collectionId = collectionId
            self.detectionAttributes = detectionAttributes
        }

        private enum CodingKeys: String, CodingKey {
            case image = "Image"
            case externalImageId = "ExternalImageId"
            case collectionId = "CollectionId"
            case detectionAttributes = "DetectionAttributes"
        }
    }

}